{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "-LNWLq2zhvUz",
      "metadata": {
        "id": "-LNWLq2zhvUz"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "Ysa-7eLvEMpE",
      "metadata": {
        "id": "Ysa-7eLvEMpE"
      },
      "source": [
        "# Gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9GJAW8qAEM8f",
      "metadata": {
        "id": "9GJAW8qAEM8f"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FcIdAmrNERw-",
      "metadata": {
        "id": "FcIdAmrNERw-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m8CIB8vltFfH",
      "metadata": {
        "id": "m8CIB8vltFfH"
      },
      "source": [
        "# Set_Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EB5RqjoAtFwl",
      "metadata": {
        "id": "EB5RqjoAtFwl"
      },
      "outputs": [],
      "source": [
        "strategy   = 'Kalman'\n",
        "process    = 'Train'\n",
        "symbol     = 'XAUUSD'\n",
        "direction  = 'Short'\n",
        "time_frame = 'M5'\n",
        "\n",
        "root_data = f'/content/drive/MyDrive/Course Folder/Forex/XAUUSD/'\n",
        "print(root_data)\n",
        "\n",
        "rolling_window = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eaf03429",
      "metadata": {
        "id": "eaf03429"
      },
      "source": [
        "# Import_Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "R9bTNmBwK_Up",
      "metadata": {
        "id": "R9bTNmBwK_Up"
      },
      "outputs": [],
      "source": [
        "!pip install ta-lib\n",
        "import talib as ta\n",
        "print(ta.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bda1a01c",
      "metadata": {
        "id": "bda1a01c"
      },
      "outputs": [],
      "source": [
        "# Import libraries for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from datetime import timedelta\n",
        "\n",
        "# For machine learning models\n",
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split # Import train_test_split\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Import matplotlib as an alias plt and set the style\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "# Import sys to append the path for custom function file\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cgMmtFUWz0c"
      },
      "outputs": [],
      "source": [
        "def confusion_probability_summary(y_true, y_pred, positive_class_probabilities, positive_class=1):\n",
        "    \"\"\"\n",
        "    Calculate summary statistics of predicted probabilities for each outcome in a confusion matrix.\n",
        "    \"\"\"\n",
        "    data = pd.DataFrame({\n",
        "        'actual': np.asarray(y_true),\n",
        "        'predicted': np.asarray(y_pred),\n",
        "        'prob_positive': np.asarray(positive_class_probabilities),\n",
        "    })\n",
        "\n",
        "    outcomes = {\n",
        "        'True Positive': (data['actual'] == positive_class) & (data['predicted'] == positive_class),\n",
        "        'False Positive': (data['actual'] != positive_class) & (data['predicted'] == positive_class),\n",
        "        'True Negative': (data['actual'] != positive_class) & (data['predicted'] != positive_class),\n",
        "        'False Negative': (data['actual'] == positive_class) & (data['predicted'] != positive_class),\n",
        "    }\n",
        "\n",
        "    summary_rows = []\n",
        "    for outcome, mask in outcomes.items():\n",
        "        probabilities = data.loc[mask, 'prob_positive']\n",
        "        summary_rows.append({\n",
        "            'Outcome': outcome,\n",
        "            'Count': int(probabilities.count()),\n",
        "            'Mean Probability': probabilities.mean() if not probabilities.empty else np.nan,\n",
        "            'Std Probability': probabilities.std(ddof=0) if probabilities.count() > 1 else np.nan,\n",
        "        })\n",
        "\n",
        "    summary = pd.DataFrame(summary_rows).set_index('Outcome')\n",
        "    return summary\n"
      ],
      "id": "7cgMmtFUWz0c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DMuFtzf54JN8",
      "metadata": {
        "id": "DMuFtzf54JN8"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "zhTndYVi1TEV",
      "metadata": {
        "id": "zhTndYVi1TEV"
      },
      "source": [
        "# Support Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "FYEryjzTLPf8",
      "metadata": {
        "id": "FYEryjzTLPf8"
      },
      "outputs": [],
      "source": [
        "def results(data, pnl_column='PnL'):\n",
        "    # Calculate the metrics\n",
        "    time_difference = data.index.max() - data.index.min()\n",
        "    days = time_difference.days\n",
        "    total_trades = data[data['Open_Trade'].notna() & (data['Open_Trade'] != 0)].shape[0]\n",
        "    profit_trades = data[data[pnl_column] > 0].shape[0]\n",
        "    loss_trades = data[data[pnl_column] < 0].shape[0]\n",
        "    profits = data[data[pnl_column] > 0][pnl_column].sum()\n",
        "    losses = data[data[pnl_column] < 0][pnl_column].sum()\n",
        "\n",
        "    # Create a dictionary with the results\n",
        "    results_dict = {\n",
        "        'days': days,\n",
        "        'total_trades': total_trades,\n",
        "        '': '',\n",
        "        'income': profits,\n",
        "        'losses': losses,\n",
        "        'profits': profits + losses,\n",
        "        ' ':' ',\n",
        "        'profit_trades': profit_trades,\n",
        "        'loss_trades': loss_trades,\n",
        "        '  ':'  ',\n",
        "        '% Win_Trades': profit_trades / (profit_trades + loss_trades) * 100 if (profit_trades + loss_trades) > 0 else 0,\n",
        "        '% Loss_Trades': loss_trades / (profit_trades + loss_trades)*100 if (profit_trades + loss_trades) > 0 else 0\n",
        "    }\n",
        "\n",
        "    # Create a DataFrame from the dictionary and transpose it\n",
        "    perf_metrics = pd.DataFrame([results_dict]).T\n",
        "\n",
        "    # Rename the column\n",
        "    perf_metrics.rename(columns={0: 'Results'}, inplace=True)\n",
        "\n",
        "    # Format the DataFrame for display\n",
        "    perf_metrics.loc[['days', 'total_trades', 'profit_trades', 'loss_trades','% Win_Trades','% Loss_Trades'], 'Results'] = perf_metrics.loc[['days', 'total_trades', 'profit_trades', 'loss_trades','% Win_Trades','% Loss_Trades'], 'Results'].apply(lambda x: f\"{x:,.0f}\" if pd.notna(x) else '')\n",
        "    perf_metrics.loc[['income', 'losses', 'profits'], 'Results'] = perf_metrics.loc[['income', 'losses', 'profits'], 'Results'].apply(lambda x: f\"${x:,.2f}\" if pd.notna(x) else '')\n",
        "\n",
        "    return perf_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fB8uDm2F1TS1",
      "metadata": {
        "id": "fB8uDm2F1TS1"
      },
      "outputs": [],
      "source": [
        "def create_features(train_data, index):\n",
        "    short_periods = [3, 5, 7, 10, 15, 17]\n",
        "    long_periods = [20, 22, 66, 126, 252]\n",
        "    periods = short_periods + long_periods\n",
        "\n",
        "    features = pd.DataFrame(index=index)\n",
        "\n",
        "    # Indicators that do not depend on the lookback period\n",
        "    features['OBV'] = ta.OBV(train_data['Close'], train_data['Volume'])\n",
        "    features['AD'] = ta.AD(train_data['High'], train_data['Low'],\n",
        "                           train_data['Close'], train_data['Volume'])\n",
        "\n",
        "    # Pre-compute moving averages to avoid repeated calculations\n",
        "    sma = {p: ta.SMA(train_data['Close'], timeperiod=p) for p in periods}\n",
        "    ema = {p: ta.EMA(train_data['Close'], timeperiod=p) for p in periods}\n",
        "\n",
        "    for period in periods:\n",
        "        features[f'RSI_{period}'] = ta.RSI(train_data['Close'], timeperiod=period)\n",
        "        features[f'MFI_{period}'] = ta.MFI(train_data['High'], train_data['Low'],\n",
        "                                           train_data['Close'], train_data['Volume'],\n",
        "                                           timeperiod=period)\n",
        "        features[f'ADX_{period}'] = ta.ADX(train_data['High'], train_data['Low'],\n",
        "                                           train_data['Close'], timeperiod=period)\n",
        "        features[f'ROCP_{period}'] = ta.ROCP(train_data['Close'], timeperiod=period)\n",
        "\n",
        "    for s in short_periods:\n",
        "        for l in long_periods:\n",
        "            features[f'SMA_Crossover_{s}_{l}'] = sma[s] - sma[l]\n",
        "            features[f'EMA_Crossover_{s}_{l}'] = ema[s] - ema[l]\n",
        "\n",
        "    features.dropna(inplace=True)\n",
        "    return features\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "196899d1",
      "metadata": {
        "id": "196899d1"
      },
      "outputs": [],
      "source": [
        "def strategy_returns_dynamic_different_thresholds(prices, threshold):\n",
        "    rolling = prices['Rolling Returns'].to_numpy()\n",
        "    yearly_std = prices['Yearly Stdev'].to_numpy()\n",
        "    pct_change = prices['Close'].pct_change().to_numpy()\n",
        "    signals = np.zeros(len(prices), dtype=np.int8)\n",
        "\n",
        "    curr_pos = 0\n",
        "    hold_days = 0\n",
        "    for i in range(len(prices)):\n",
        "        if curr_pos == 0 or hold_days == 20:\n",
        "            thresh_val = threshold * yearly_std[i]\n",
        "            if rolling[i] >= thresh_val:\n",
        "                curr_pos = 1\n",
        "                hold_days = 0\n",
        "            elif rolling[i] < -thresh_val:\n",
        "                curr_pos = -1\n",
        "                hold_days = 0\n",
        "            else:\n",
        "                curr_pos = 0\n",
        "                hold_days = 0\n",
        "        else:\n",
        "            hold_days += 1\n",
        "        signals[i] = curr_pos\n",
        "\n",
        "    prices[f'Signal_{threshold}'] = signals\n",
        "    strategy_returns = pct_change * np.roll(signals, 1)\n",
        "    prices[f'Strategy Returns_{threshold}'] = strategy_returns\n",
        "    return np.cumprod(strategy_returns + 1)\n",
        "\n",
        "\n",
        "def strategy_returns_different_thresholds(prices, threshold):\n",
        "    rolling = prices['Rolling Returns'].to_numpy()\n",
        "    pct_change = prices['Close'].pct_change().to_numpy()\n",
        "    signals = np.zeros(len(prices), dtype=np.int8)\n",
        "\n",
        "    curr_pos = 0\n",
        "    hold_days = 0\n",
        "    for i in range(len(prices)):\n",
        "        if curr_pos == 0 or hold_days == 20:\n",
        "            if rolling[i] >= threshold:\n",
        "                curr_pos = 1\n",
        "                hold_days = 0\n",
        "            elif rolling[i] < threshold:\n",
        "                curr_pos = -1\n",
        "                hold_days = 0\n",
        "        else:\n",
        "            hold_days += 1\n",
        "        signals[i] = curr_pos\n",
        "\n",
        "    prices[f'Signal_{threshold}'] = signals\n",
        "    strategy_returns = pct_change * np.roll(signals, 1)\n",
        "    prices[f'Strategy Returns_{threshold}'] = strategy_returns\n",
        "    return np.cumprod(strategy_returns + 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ZOg20zC2Gei",
      "metadata": {
        "id": "0ZOg20zC2Gei"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dyGl1MUHVebJ",
      "metadata": {
        "id": "dyGl1MUHVebJ"
      },
      "outputs": [],
      "source": [
        "data_type = 'Scale'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "oZ4oncRY2Kv_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZ4oncRY2Kv_",
        "outputId": "2abd6ebc-9fb1-4af9-812e-3f1190f35f52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The train_data DataFrame covers a period of 2396 days.\n"
          ]
        }
      ],
      "source": [
        "### Open OHLC dataframe\n",
        "\n",
        "ohlc = pd.read_csv(root_data + 'Data/'+symbol+'_M5.csv', index_col=0)\n",
        "ohlc.index = pd.to_datetime(ohlc.index)\n",
        "time_difference = ohlc.index.max() - ohlc.index.min()\n",
        "number_of_days = time_difference.days\n",
        "\n",
        "print(f\"The train_data DataFrame covers a period of {number_of_days} days.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vZHp1PgT2L7e",
      "metadata": {
        "id": "vZHp1PgT2L7e"
      },
      "outputs": [],
      "source": [
        "### Features\n",
        "\n",
        "features_5m = pd.read_csv(root_data + 'Results/'+symbol+'_'+direction+'_M5M10_'+data_type+'_Features.csv', index_col=0)\n",
        "features_5m['Date'] = features_5m.index\n",
        "features_5m['Date'] = pd.to_datetime(features_5m['Date'])\n",
        "features_5m.set_index(\"Date\", inplace=True)\n",
        "\n",
        "print(list(features_5m.columns),'\\n')\n",
        "print('Shape = ',features_5m.shape)\n",
        "\n",
        "features_5m.tail(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "XM2K_2T22n2k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM2K_2T22n2k",
        "outputId": "5e25ba7b-d08b-42db-b25d-b9db34b36a90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Open', 'High', 'Low', 'Close', 'Volume', 'Spread', 'ATR', 'kal_1', 'kal_2', 'kal_3', 'kal_4', 'Open_Trade', 'Entry_Date', 'Type', 'Trade_Number', 'st_Exit_Date', 'trade type', 'st_Duration', 'st_row_PnL_close', 'st_row_PnL_high', 'st_row_PnL_low', 'st_Max', 'st_Min', 'st_PnL', 'st_atr_PnL', 'st_atr_max_PnL', 'atr_mult_close', 'atr_mult_high', 'atr_mult_low', 'atr_dyn', 'atr_PnL', 'atr_Exit_Date', 'atr_Duration', 'atr_PnL_dollar', 'atr_H_dyn', 'atr_H_PnL', 'atr_H_Exit_Date', 'atr_H_Duration', 'atr_H_PnL_dollar'] \n",
            "\n",
            "Shape :  (20000, 39) \n",
            "\n",
            "Missing values (NaN and Inf) in lab sorted by highest to lowest:\n",
            "atr_PnL_dollar      18148\n",
            "atr_Duration        18148\n",
            "atr_Exit_Date       18148\n",
            "atr_PnL             18148\n",
            "st_Duration         17193\n",
            "st_Max              17193\n",
            "st_Min              17193\n",
            "atr_H_Duration      17193\n",
            "atr_H_Exit_Date     17193\n",
            "st_PnL              17193\n",
            "atr_H_PnL           17193\n",
            "atr_H_PnL_dollar    17193\n",
            "st_Exit_Date        17193\n",
            "Open_Trade          17192\n",
            "Entry_Date          17192\n",
            "Type                17192\n",
            "atr_dyn             15639\n",
            "atr_H_dyn           14658\n",
            "atr_mult_high           4\n",
            "atr_mult_low            4\n",
            "atr_mult_close          4\n",
            "st_row_PnL_close        3\n",
            "st_row_PnL_low          3\n",
            "st_row_PnL_high         3\n",
            "trade type              1\n",
            "st_atr_PnL              1\n",
            "Trade_Number            1\n",
            "st_atr_max_PnL          1\n",
            "Low                     0\n",
            "Open                    0\n",
            "High                    0\n",
            "ATR                     0\n",
            "Spread                  0\n",
            "Volume                  0\n",
            "Close                   0\n",
            "kal_4                   0\n",
            "kal_3                   0\n",
            "kal_2                   0\n",
            "kal_1                   0\n",
            "dtype: int64\n",
            "Total missing value count in lab: 309227\n"
          ]
        }
      ],
      "source": [
        "### Labels\n",
        "\n",
        "lab = pd.read_csv(root_data + 'Results/'+symbol+'_'+strategy+'_'+time_frame+'_Strategy_Gen_Labels.csv', index_col=0)\n",
        "lab['Date'] = pd.to_datetime(lab['Date'])\n",
        "lab.set_index('Date', inplace=True)\n",
        "\n",
        "columns_to_drop = ['st_row_PnL_Low','Close_Trade']\n",
        "lab = lab.drop(columns=columns_to_drop)\n",
        "\n",
        "print(list(lab.columns),'\\n')\n",
        "print('Shape : ',lab.shape,'\\n')\n",
        "\n",
        "nan_counts = lab.isnull().sum()\n",
        "total_missing_counts = nan_counts\n",
        "\n",
        "print(\"Missing values (NaN and Inf) in lab sorted by highest to lowest:\")\n",
        "print(total_missing_counts.sort_values(ascending=False))\n",
        "print(\"Total missing value count in lab:\", total_missing_counts.sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "IA2-iSWJ9Udm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA2-iSWJ9Udm",
        "outputId": "2d09f8fd-29e1-4454-e165-f05c06a9ba58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['label', 'Open_Trade', '10min_RSI_3_diff', '10min_RSI_3', '10min_Close_Kal_300', 'Close_Kal_300', '10min_slope_div_300_3_diff', 'slope_angle_300_6', 'MFI_7_diff', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_3', 'slope_div_300_6 - slope_div_300_9', '10min_slope_signal_600_6', 'slope_lin_reg_signal_300_3', 'slope_lin_reg_600_9_diff', 'slope_angle_600_9_diff', 'slope_signal_300_6_diff', '10min_slope_signal_900_9_diff', 'Kal_600_minus_Kal_900', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9', '10min_slope_angle_600_3_diff', '10min_slope_lin_reg_signal_600_6', '10min_MFI_7_diff', '10min_RSI_7', '10min_slope_lin_reg_signal_900_3_diff', '10min_slope_lin_reg_signal_300_9', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_9', 'MFI_3_diff', '10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_3', '10min_slope_angle_300_3 - slope_angle_900_6', 'slope_signal_600_6 - slope_signal_900_6', '10min_slope_angle_900_9_diff', '10min_slope_angle_300_9_diff', 'slope_signal_600_3 - slope_signal_900_3', 'slope_signal_900_6', 'slope_signal_600_3 - slope_signal_600_9', '10min_slope_signal_600_3 - slope_signal_900_6', 'slope_signal_900_3_diff', '10min_slope_signal_300_3 - slope_signal_900_6', '10min_slope_signal_600_9 - slope_signal_900_6', '10min_slope_angle_300_3_diff', '10min_slope_signal_300_9', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9', 'slope_div_300_3 - slope_div_900_6', 'slope_signal_300_3 - slope_signal_600_9', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_6 - slope_signal_300_9', 'OBV_diff', 'slope_signal_300_6 - slope_signal_600_9', '10min_slope_signal_600_3 - slope_signal_900_3', '10min_Kal_change_600', '10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_600_3', 'slope_lin_reg_300_3 - slope_lin_reg_600_9', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6', 'slope_signal_300_9 - slope_signal_600_6', '10min_slope_signal_300_6_diff', '10min_slope_lin_reg_signal_600_9_diff', 'slope_lin_reg_signal_900_9_diff', 'slope_signal_300_3 - slope_signal_300_9', 'slope_signal_300_6 - slope_signal_600_6', 'MFI_14_diff', 'RSI_7', '10min_slope_signal_300_3 - slope_signal_900_3', 'slope_lin_reg_300_6_diff', '10min_slope_signal_300_6 - slope_signal_900_6', 'slope_angle_300_6_diff', '10min_slope_angle_600_6_diff', '10min_slope_lin_reg_signal_600_6_diff', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_9', '10min_slope_signal_600_9_diff', 'slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9', 'slope_signal_300_9_diff', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6', 'slope_angle_600_6 - slope_angle_900_6', '10min_slope_lin_reg_signal_900_9', 'slope_angle_300_3_diff', '10min_slope_signal_300_3 - slope_signal_300_9', '10min_slope_signal_600_6 - slope_signal_900_6', 'slope_div_600_3', '10min_slope_signal_300_3 - slope_signal_600_9', '10min_slope_angle_600_6 - slope_angle_900_9', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3', '10min_slope_signal_600_3', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3', 'slope_angle_600_6 - slope_angle_600_9', '10min_MFI_3_diff', '10min_slope_lin_reg_300_3 - slope_lin_reg_600_9', 'slope_angle_300_6 - slope_angle_600_6', '10min_Kal_change_300', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_600_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_3', 'slope_signal_300_3 - slope_signal_600_3', '10min_MFI_14_diff', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_6', '10min_slope_lin_reg_signal_600_3_diff', 'slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_9', 'slope_signal_600_3 - slope_signal_900_9', '10min_slope_angle_600_3 - slope_angle_600_6', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_300_9', '10min_OBV_diff', '10min_MFI_7 - MFI_14', '10min_slope_signal_300_3 - slope_signal_300_6', '10min_slope_signal_300_3_diff', 'slope_angle_300_6 - slope_angle_300_9', 'slope_angle_900_6', 'slope_angle_300_3 - slope_angle_300_6', '10min_slope_signal_300_3 - slope_signal_600_3', 'slope_signal_300_3 - slope_signal_900_6', 'slope_lin_reg_300_3 - slope_lin_reg_600_3', '10min_slope_signal_900_9', '10min_slope_signal_300_6 - slope_signal_600_9', '10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9', 'slope_angle_300_3 - slope_angle_600_9', 'slope_div_300_6_diff', '10min_slope_signal_300_9_diff', 'slope_lin_reg_300_3_diff', 'slope_lin_reg_signal_300_6', 'slope_lin_reg_signal_900_9', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_6', '10min_slope_angle_900_6_diff', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3', 'slope_angle_300_6 - slope_angle_600_9', 'slope_signal_300_3 - slope_signal_900_9', '10min_slope_angle_300_6 - slope_angle_300_9', '10min_slope_signal_300_6', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_6', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_3', '10min_slope_angle_300_3 - slope_angle_600_3', '10min_slope_angle_600_9_diff', 'slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9', 'OBV', 'slope_lin_reg_signal_600_3_diff', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_9 - slope_signal_600_6', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_9', 'slope_signal_600_9 - slope_signal_900_9', 'slope_angle_900_9_diff', '10min_Kal_300', '10min_MFI_7', 'slope_angle_300_9_diff', '10min_MFI_3', '10min_slope_angle_300_6_diff', 'slope_div_300_6 - slope_div_600_9', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_900_6_diff', 'slope_signal_600_3', 'slope_signal_300_3 - slope_signal_600_6', '10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3', '10min_slope_angle_600_6 - slope_angle_600_9', 'slope_signal_600_6 - slope_signal_600_9', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_3', 'RSI_3_diff', '10min_RSI_3 - RSI_7', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_6', 'Kal_300', '10min_slope_angle_300_3 - slope_angle_300_9', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9', 'slope_angle_600_6', '10min_slope_signal_600_9 - slope_signal_900_9', 'slope_signal_600_6 - slope_signal_900_9', '10min_slope_angle_300_3 - slope_angle_900_9', 'slope_signal_600_3 - slope_signal_900_6', 'slope_lin_reg_signal_300_9', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9', '10min_slope_lin_reg_signal_900_9_diff', '10min_MFI_14', '10min_slope_signal_900_3_diff', '10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9', '10min_slope_lin_reg_signal_600_9', 'MFI_3 - MFI_7', 'slope_angle_600_9 - slope_angle_900_9', 'slope_signal_300_3 - slope_signal_900_3', 'RSI_14', 'Kal_change_300', 'slope_signal_300_6 - slope_signal_300_9', '10min_slope_lin_reg_signal_900_3', '10min_slope_angle_300_3 - slope_angle_300_6', 'slope_signal_900_6 - slope_signal_900_9', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_3', 'slope_lin_reg_signal_600_3', 'slope_signal_900_9_diff', '10min_slope_div_300_3 - slope_div_900_6', '10min_slope_signal_900_6', '10min_slope_signal_900_6 - slope_signal_900_9', 'slope_signal_300_6 - slope_signal_900_6', 'slope_signal_600_6', '10min_slope_div_300_3 - slope_div_600_6', 'slope_angle_900_6_diff', 'slope_div_300_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_6', '10min_slope_angle_300_6 - slope_angle_600_6', '10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6', 'slope_lin_reg_600_6_diff', 'slope_lin_reg_signal_900_6', '10min_slope_signal_300_6 - slope_signal_900_9', '10min_slope_lin_reg_signal_300_9_diff', '10min_RSI_7 - RSI_14', '10min_slope_signal_600_9', '10min_slope_signal_300_6 - slope_signal_600_6', 'slope_signal_600_9', 'slope_signal_600_9 - slope_signal_900_6', 'slope_signal_600_3 - slope_signal_600_6', '10min_slope_angle_600_9 - slope_angle_900_9', '10min_OBV', 'slope_lin_reg_signal_900_3', 'slope_angle_300_9 - slope_angle_600_9', '10min_slope_signal_600_3 - slope_signal_600_6', 'slope_div_300_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9', 'slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6', '10min_slope_angle_300_3 - slope_angle_600_9', 'slope_signal_300_6 - slope_signal_600_3', 'slope_signal_900_6_diff', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9', '10min_slope_signal_600_6 - slope_signal_600_9', 'slope_angle_600_3 - slope_angle_900_3', '10min_slope_signal_300_3 - slope_signal_900_9', '10min_slope_div_300_3 - slope_div_300_6', 'slope_signal_600_9_diff', 'slope_angle_300_3 - slope_angle_600_6', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_9', '10min_slope_signal_600_6_diff', 'slope_signal_300_3_diff', 'slope_signal_300_9 - slope_signal_600_9', '10min_slope_angle_600_6 - slope_angle_900_6'] \n",
            "\n",
            "Shape =  (2808, 236) \n",
            "\n",
            "Label_Counts =  label\n",
            "1    1520\n",
            "0    1288\n",
            "Name: count, dtype: int64 \n",
            "\n",
            "Missing values (NaN and Inf) in feat_obj sorted by highest to lowest AFTER DROPPING COLUMNS:\n",
            "label                                                      0\n",
            "Open_Trade                                                 0\n",
            "10min_RSI_3_diff                                           0\n",
            "10min_RSI_3                                                0\n",
            "10min_Close_Kal_300                                        0\n",
            "                                                          ..\n",
            "slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_9    0\n",
            "10min_slope_signal_600_6_diff                              0\n",
            "slope_signal_300_3_diff                                    0\n",
            "slope_signal_300_9 - slope_signal_600_9                    0\n",
            "10min_slope_angle_600_6 - slope_angle_900_6                0\n",
            "Length: 236, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "### Merge\n",
        "\n",
        "feat_obj = features_5m.copy()\n",
        "\n",
        "print(list(feat_obj.columns),'\\n')\n",
        "print('Shape = ',feat_obj.shape,'\\n')\n",
        "print('Label_Counts = ', feat_obj['label'].value_counts(),'\\n')\n",
        "\n",
        "feat_obj.dropna(inplace=True)\n",
        "\n",
        "nan_counts = feat_obj.isnull().sum()\n",
        "\n",
        "print(\"Missing values (NaN and Inf) in feat_obj sorted by highest to lowest AFTER DROPPING COLUMNS:\")\n",
        "\n",
        "nan_counts_after = feat_obj.isnull().sum()\n",
        "inf_counts_after = np.isinf(feat_obj.select_dtypes(include=np.number)).sum()\n",
        "total_missing_counts_after = nan_counts_after + inf_counts_after\n",
        "print(total_missing_counts_after.sort_values(ascending=False))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "U1SDwIIeNhhU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1SDwIIeNhhU",
        "outputId": "e14281a4-7152-451a-ace0-362361d13fb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of train_data: (1965, 236)\n",
            "Shape of test_data: (843, 236)\n"
          ]
        }
      ],
      "source": [
        "# Split the data into 70% train and 30% test based on index\n",
        "train_size = int(0.7 * len(feat_obj))\n",
        "train = feat_obj.iloc[:train_size]\n",
        "test  = feat_obj.iloc[train_size:]\n",
        "\n",
        "print(\"Shape of train_data:\", train.shape)\n",
        "print(\"Shape of test_data:\", test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "5KnO-8hT71wu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KnO-8hT71wu",
        "outputId": "e6fe7f0f-cad7-4ab7-f8e0-e306ca1887ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_Min_Date 2025-04-15 04:25:00\n",
            "Train_Max_Date 2025-06-25 18:25:00 \n",
            "\n",
            "Test_Min_Date 2025-06-25 18:40:00\n",
            "Test_Max_Date 2025-07-25 23:45:00 \n",
            "\n",
            "Train_Columns :  ['label', 'Open_Trade', '10min_RSI_3_diff', '10min_RSI_3', '10min_Close_Kal_300', 'Close_Kal_300', '10min_slope_div_300_3_diff', 'slope_angle_300_6', 'MFI_7_diff', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_3', 'slope_div_300_6 - slope_div_300_9', '10min_slope_signal_600_6', 'slope_lin_reg_signal_300_3', 'slope_lin_reg_600_9_diff', 'slope_angle_600_9_diff', 'slope_signal_300_6_diff', '10min_slope_signal_900_9_diff', 'Kal_600_minus_Kal_900', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9', '10min_slope_angle_600_3_diff', '10min_slope_lin_reg_signal_600_6', '10min_MFI_7_diff', '10min_RSI_7', '10min_slope_lin_reg_signal_900_3_diff', '10min_slope_lin_reg_signal_300_9', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_9', 'MFI_3_diff', '10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_3', '10min_slope_angle_300_3 - slope_angle_900_6', 'slope_signal_600_6 - slope_signal_900_6', '10min_slope_angle_900_9_diff', '10min_slope_angle_300_9_diff', 'slope_signal_600_3 - slope_signal_900_3', 'slope_signal_900_6', 'slope_signal_600_3 - slope_signal_600_9', '10min_slope_signal_600_3 - slope_signal_900_6', 'slope_signal_900_3_diff', '10min_slope_signal_300_3 - slope_signal_900_6', '10min_slope_signal_600_9 - slope_signal_900_6', '10min_slope_angle_300_3_diff', '10min_slope_signal_300_9', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9', 'slope_div_300_3 - slope_div_900_6', 'slope_signal_300_3 - slope_signal_600_9', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_6 - slope_signal_300_9', 'OBV_diff', 'slope_signal_300_6 - slope_signal_600_9', '10min_slope_signal_600_3 - slope_signal_900_3', '10min_Kal_change_600', '10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_600_3', 'slope_lin_reg_300_3 - slope_lin_reg_600_9', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6', 'slope_signal_300_9 - slope_signal_600_6', '10min_slope_signal_300_6_diff', '10min_slope_lin_reg_signal_600_9_diff', 'slope_lin_reg_signal_900_9_diff', 'slope_signal_300_3 - slope_signal_300_9', 'slope_signal_300_6 - slope_signal_600_6', 'MFI_14_diff', 'RSI_7', '10min_slope_signal_300_3 - slope_signal_900_3', 'slope_lin_reg_300_6_diff', '10min_slope_signal_300_6 - slope_signal_900_6', 'slope_angle_300_6_diff', '10min_slope_angle_600_6_diff', '10min_slope_lin_reg_signal_600_6_diff', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_9', '10min_slope_signal_600_9_diff', 'slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9', 'slope_signal_300_9_diff', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6', 'slope_angle_600_6 - slope_angle_900_6', '10min_slope_lin_reg_signal_900_9', 'slope_angle_300_3_diff', '10min_slope_signal_300_3 - slope_signal_300_9', '10min_slope_signal_600_6 - slope_signal_900_6', 'slope_div_600_3', '10min_slope_signal_300_3 - slope_signal_600_9', '10min_slope_angle_600_6 - slope_angle_900_9', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3', '10min_slope_signal_600_3', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3', 'slope_angle_600_6 - slope_angle_600_9', '10min_MFI_3_diff', '10min_slope_lin_reg_300_3 - slope_lin_reg_600_9', 'slope_angle_300_6 - slope_angle_600_6', '10min_Kal_change_300', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_600_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_3', 'slope_signal_300_3 - slope_signal_600_3', '10min_MFI_14_diff', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_6', '10min_slope_lin_reg_signal_600_3_diff', 'slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_9', 'slope_signal_600_3 - slope_signal_900_9', '10min_slope_angle_600_3 - slope_angle_600_6', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_300_9', '10min_OBV_diff', '10min_MFI_7 - MFI_14', '10min_slope_signal_300_3 - slope_signal_300_6', '10min_slope_signal_300_3_diff', 'slope_angle_300_6 - slope_angle_300_9', 'slope_angle_900_6', 'slope_angle_300_3 - slope_angle_300_6', '10min_slope_signal_300_3 - slope_signal_600_3', 'slope_signal_300_3 - slope_signal_900_6', 'slope_lin_reg_300_3 - slope_lin_reg_600_3', '10min_slope_signal_900_9', '10min_slope_signal_300_6 - slope_signal_600_9', '10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9', 'slope_angle_300_3 - slope_angle_600_9', 'slope_div_300_6_diff', '10min_slope_signal_300_9_diff', 'slope_lin_reg_300_3_diff', 'slope_lin_reg_signal_300_6', 'slope_lin_reg_signal_900_9', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_6', '10min_slope_angle_900_6_diff', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3', 'slope_angle_300_6 - slope_angle_600_9', 'slope_signal_300_3 - slope_signal_900_9', '10min_slope_angle_300_6 - slope_angle_300_9', '10min_slope_signal_300_6', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_6', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_3', '10min_slope_angle_300_3 - slope_angle_600_3', '10min_slope_angle_600_9_diff', 'slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9', 'OBV', 'slope_lin_reg_signal_600_3_diff', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_9 - slope_signal_600_6', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_9', 'slope_signal_600_9 - slope_signal_900_9', 'slope_angle_900_9_diff', '10min_Kal_300', '10min_MFI_7', 'slope_angle_300_9_diff', '10min_MFI_3', '10min_slope_angle_300_6_diff', 'slope_div_300_6 - slope_div_600_9', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_900_6_diff', 'slope_signal_600_3', 'slope_signal_300_3 - slope_signal_600_6', '10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3', '10min_slope_angle_600_6 - slope_angle_600_9', 'slope_signal_600_6 - slope_signal_600_9', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_3', 'RSI_3_diff', '10min_RSI_3 - RSI_7', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_6', 'Kal_300', '10min_slope_angle_300_3 - slope_angle_300_9', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9', 'slope_angle_600_6', '10min_slope_signal_600_9 - slope_signal_900_9', 'slope_signal_600_6 - slope_signal_900_9', '10min_slope_angle_300_3 - slope_angle_900_9', 'slope_signal_600_3 - slope_signal_900_6', 'slope_lin_reg_signal_300_9', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9', '10min_slope_lin_reg_signal_900_9_diff', '10min_MFI_14', '10min_slope_signal_900_3_diff', '10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9', '10min_slope_lin_reg_signal_600_9', 'MFI_3 - MFI_7', 'slope_angle_600_9 - slope_angle_900_9', 'slope_signal_300_3 - slope_signal_900_3', 'RSI_14', 'Kal_change_300', 'slope_signal_300_6 - slope_signal_300_9', '10min_slope_lin_reg_signal_900_3', '10min_slope_angle_300_3 - slope_angle_300_6', 'slope_signal_900_6 - slope_signal_900_9', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_3', 'slope_lin_reg_signal_600_3', 'slope_signal_900_9_diff', '10min_slope_div_300_3 - slope_div_900_6', '10min_slope_signal_900_6', '10min_slope_signal_900_6 - slope_signal_900_9', 'slope_signal_300_6 - slope_signal_900_6', 'slope_signal_600_6', '10min_slope_div_300_3 - slope_div_600_6', 'slope_angle_900_6_diff', 'slope_div_300_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_6', '10min_slope_angle_300_6 - slope_angle_600_6', '10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6', 'slope_lin_reg_600_6_diff', 'slope_lin_reg_signal_900_6', '10min_slope_signal_300_6 - slope_signal_900_9', '10min_slope_lin_reg_signal_300_9_diff', '10min_RSI_7 - RSI_14', '10min_slope_signal_600_9', '10min_slope_signal_300_6 - slope_signal_600_6', 'slope_signal_600_9', 'slope_signal_600_9 - slope_signal_900_6', 'slope_signal_600_3 - slope_signal_600_6', '10min_slope_angle_600_9 - slope_angle_900_9', '10min_OBV', 'slope_lin_reg_signal_900_3', 'slope_angle_300_9 - slope_angle_600_9', '10min_slope_signal_600_3 - slope_signal_600_6', 'slope_div_300_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9', 'slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6', '10min_slope_angle_300_3 - slope_angle_600_9', 'slope_signal_300_6 - slope_signal_600_3', 'slope_signal_900_6_diff', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9', '10min_slope_signal_600_6 - slope_signal_600_9', 'slope_angle_600_3 - slope_angle_900_3', '10min_slope_signal_300_3 - slope_signal_900_9', '10min_slope_div_300_3 - slope_div_300_6', 'slope_signal_600_9_diff', 'slope_angle_300_3 - slope_angle_600_6', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_9', '10min_slope_signal_600_6_diff', 'slope_signal_300_3_diff', 'slope_signal_300_9 - slope_signal_600_9', '10min_slope_angle_600_6 - slope_angle_900_6'] \n",
            "\n",
            "Test_Columns :  ['label', 'Open_Trade', '10min_RSI_3_diff', '10min_RSI_3', '10min_Close_Kal_300', 'Close_Kal_300', '10min_slope_div_300_3_diff', 'slope_angle_300_6', 'MFI_7_diff', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_3', 'slope_div_300_6 - slope_div_300_9', '10min_slope_signal_600_6', 'slope_lin_reg_signal_300_3', 'slope_lin_reg_600_9_diff', 'slope_angle_600_9_diff', 'slope_signal_300_6_diff', '10min_slope_signal_900_9_diff', 'Kal_600_minus_Kal_900', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9', '10min_slope_angle_600_3_diff', '10min_slope_lin_reg_signal_600_6', '10min_MFI_7_diff', '10min_RSI_7', '10min_slope_lin_reg_signal_900_3_diff', '10min_slope_lin_reg_signal_300_9', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_9', 'MFI_3_diff', '10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_3', '10min_slope_angle_300_3 - slope_angle_900_6', 'slope_signal_600_6 - slope_signal_900_6', '10min_slope_angle_900_9_diff', '10min_slope_angle_300_9_diff', 'slope_signal_600_3 - slope_signal_900_3', 'slope_signal_900_6', 'slope_signal_600_3 - slope_signal_600_9', '10min_slope_signal_600_3 - slope_signal_900_6', 'slope_signal_900_3_diff', '10min_slope_signal_300_3 - slope_signal_900_6', '10min_slope_signal_600_9 - slope_signal_900_6', '10min_slope_angle_300_3_diff', '10min_slope_signal_300_9', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9', 'slope_div_300_3 - slope_div_900_6', 'slope_signal_300_3 - slope_signal_600_9', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_6 - slope_signal_300_9', 'OBV_diff', 'slope_signal_300_6 - slope_signal_600_9', '10min_slope_signal_600_3 - slope_signal_900_3', '10min_Kal_change_600', '10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_600_3', 'slope_lin_reg_300_3 - slope_lin_reg_600_9', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6', 'slope_signal_300_9 - slope_signal_600_6', '10min_slope_signal_300_6_diff', '10min_slope_lin_reg_signal_600_9_diff', 'slope_lin_reg_signal_900_9_diff', 'slope_signal_300_3 - slope_signal_300_9', 'slope_signal_300_6 - slope_signal_600_6', 'MFI_14_diff', 'RSI_7', '10min_slope_signal_300_3 - slope_signal_900_3', 'slope_lin_reg_300_6_diff', '10min_slope_signal_300_6 - slope_signal_900_6', 'slope_angle_300_6_diff', '10min_slope_angle_600_6_diff', '10min_slope_lin_reg_signal_600_6_diff', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_9', '10min_slope_signal_600_9_diff', 'slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9', 'slope_signal_300_9_diff', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6', 'slope_angle_600_6 - slope_angle_900_6', '10min_slope_lin_reg_signal_900_9', 'slope_angle_300_3_diff', '10min_slope_signal_300_3 - slope_signal_300_9', '10min_slope_signal_600_6 - slope_signal_900_6', 'slope_div_600_3', '10min_slope_signal_300_3 - slope_signal_600_9', '10min_slope_angle_600_6 - slope_angle_900_9', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3', '10min_slope_signal_600_3', 'slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3', 'slope_angle_600_6 - slope_angle_600_9', '10min_MFI_3_diff', '10min_slope_lin_reg_300_3 - slope_lin_reg_600_9', 'slope_angle_300_6 - slope_angle_600_6', '10min_Kal_change_300', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_9', 'slope_lin_reg_signal_600_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_3', 'slope_signal_300_3 - slope_signal_600_3', '10min_MFI_14_diff', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_6', '10min_slope_lin_reg_signal_600_3_diff', 'slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_9', 'slope_signal_600_3 - slope_signal_900_9', '10min_slope_angle_600_3 - slope_angle_600_6', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_300_9', '10min_OBV_diff', '10min_MFI_7 - MFI_14', '10min_slope_signal_300_3 - slope_signal_300_6', '10min_slope_signal_300_3_diff', 'slope_angle_300_6 - slope_angle_300_9', 'slope_angle_900_6', 'slope_angle_300_3 - slope_angle_300_6', '10min_slope_signal_300_3 - slope_signal_600_3', 'slope_signal_300_3 - slope_signal_900_6', 'slope_lin_reg_300_3 - slope_lin_reg_600_3', '10min_slope_signal_900_9', '10min_slope_signal_300_6 - slope_signal_600_9', '10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9', 'slope_angle_300_3 - slope_angle_600_9', 'slope_div_300_6_diff', '10min_slope_signal_300_9_diff', 'slope_lin_reg_300_3_diff', 'slope_lin_reg_signal_300_6', 'slope_lin_reg_signal_900_9', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_6', '10min_slope_angle_900_6_diff', 'slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3', 'slope_angle_300_6 - slope_angle_600_9', 'slope_signal_300_3 - slope_signal_900_9', '10min_slope_angle_300_6 - slope_angle_300_9', '10min_slope_signal_300_6', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_6', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_3', '10min_slope_angle_300_3 - slope_angle_600_3', '10min_slope_angle_600_9_diff', 'slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9', 'OBV', 'slope_lin_reg_signal_600_3_diff', '10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_9 - slope_signal_600_6', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_9', 'slope_signal_600_9 - slope_signal_900_9', 'slope_angle_900_9_diff', '10min_Kal_300', '10min_MFI_7', 'slope_angle_300_9_diff', '10min_MFI_3', '10min_slope_angle_300_6_diff', 'slope_div_300_6 - slope_div_600_9', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_6', '10min_slope_lin_reg_signal_900_6_diff', 'slope_signal_600_3', 'slope_signal_300_3 - slope_signal_600_6', '10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3', '10min_slope_angle_600_6 - slope_angle_600_9', 'slope_signal_600_6 - slope_signal_600_9', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_6', '10min_slope_signal_300_3', 'RSI_3_diff', '10min_RSI_3 - RSI_7', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_6', 'Kal_300', '10min_slope_angle_300_3 - slope_angle_300_9', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9', 'slope_angle_600_6', '10min_slope_signal_600_9 - slope_signal_900_9', 'slope_signal_600_6 - slope_signal_900_9', '10min_slope_angle_300_3 - slope_angle_900_9', 'slope_signal_600_3 - slope_signal_900_6', 'slope_lin_reg_signal_300_9', 'slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9', '10min_slope_lin_reg_signal_900_9_diff', '10min_MFI_14', '10min_slope_signal_900_3_diff', '10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9', '10min_slope_lin_reg_signal_600_9', 'MFI_3 - MFI_7', 'slope_angle_600_9 - slope_angle_900_9', 'slope_signal_300_3 - slope_signal_900_3', 'RSI_14', 'Kal_change_300', 'slope_signal_300_6 - slope_signal_300_9', '10min_slope_lin_reg_signal_900_3', '10min_slope_angle_300_3 - slope_angle_300_6', 'slope_signal_900_6 - slope_signal_900_9', '10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_3', 'slope_lin_reg_signal_600_3', 'slope_signal_900_9_diff', '10min_slope_div_300_3 - slope_div_900_6', '10min_slope_signal_900_6', '10min_slope_signal_900_6 - slope_signal_900_9', 'slope_signal_300_6 - slope_signal_900_6', 'slope_signal_600_6', '10min_slope_div_300_3 - slope_div_600_6', 'slope_angle_900_6_diff', 'slope_div_300_3', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_6', '10min_slope_angle_300_6 - slope_angle_600_6', '10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6', 'slope_lin_reg_600_6_diff', 'slope_lin_reg_signal_900_6', '10min_slope_signal_300_6 - slope_signal_900_9', '10min_slope_lin_reg_signal_300_9_diff', '10min_RSI_7 - RSI_14', '10min_slope_signal_600_9', '10min_slope_signal_300_6 - slope_signal_600_6', 'slope_signal_600_9', 'slope_signal_600_9 - slope_signal_900_6', 'slope_signal_600_3 - slope_signal_600_6', '10min_slope_angle_600_9 - slope_angle_900_9', '10min_OBV', 'slope_lin_reg_signal_900_3', 'slope_angle_300_9 - slope_angle_600_9', '10min_slope_signal_600_3 - slope_signal_600_6', 'slope_div_300_6', '10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9', 'slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6', '10min_slope_angle_300_3 - slope_angle_600_9', 'slope_signal_300_6 - slope_signal_600_3', 'slope_signal_900_6_diff', 'slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9', '10min_slope_signal_600_6 - slope_signal_600_9', 'slope_angle_600_3 - slope_angle_900_3', '10min_slope_signal_300_3 - slope_signal_900_9', '10min_slope_div_300_3 - slope_div_300_6', 'slope_signal_600_9_diff', 'slope_angle_300_3 - slope_angle_600_6', '10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3', 'slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_9', '10min_slope_signal_600_6_diff', 'slope_signal_300_3_diff', 'slope_signal_300_9 - slope_signal_600_9', '10min_slope_angle_600_6 - slope_angle_900_6']\n"
          ]
        }
      ],
      "source": [
        "### Define Train dataframe\n",
        "\n",
        "print('Train_Min_Date', train.index.min())\n",
        "print('Train_Max_Date', train.index.max(),'\\n')\n",
        "\n",
        "print('Test_Min_Date', test.index.min())\n",
        "print('Test_Max_Date', test.index.max(),'\\n')\n",
        "\n",
        "print('Train_Columns : ',list(train.columns), '\\n')\n",
        "print('Test_Columns : ',list(test.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61614b7f",
      "metadata": {
        "id": "61614b7f"
      },
      "source": [
        "# Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "JXY2HFrnLIwW",
      "metadata": {
        "id": "JXY2HFrnLIwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "39c94c90-cfea-4312-c876-9d9aab20c56d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'st_PnL'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'st_PnL'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3012860354.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnl_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'st_PnL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-2176107095.py\u001b[0m in \u001b[0;36mresults\u001b[0;34m(data, pnl_column)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_difference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtotal_trades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open_Trade'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Open_Trade'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprofit_trades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpnl_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mloss_trades\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpnl_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprofits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpnl_column\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpnl_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'st_PnL'"
          ]
        }
      ],
      "source": [
        "results(train, pnl_column='st_PnL')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oQLNnk7XLUiJ",
      "metadata": {
        "id": "oQLNnk7XLUiJ"
      },
      "outputs": [],
      "source": [
        "results(test, pnl_column= 'st_PnL')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85449914",
      "metadata": {
        "id": "85449914"
      },
      "source": [
        "\n",
        "# ML\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6x4lfhG3E2eq",
      "metadata": {
        "id": "6x4lfhG3E2eq"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "ceaa6efa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ceaa6efa",
        "outputId": "518586c4-c544-4568-9d0f-91bc275e302e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (1375, 234)\n",
            "Shape of X_test: (590, 234)\n",
            "Shape of y_train: (1375,)\n",
            "Shape of y_test: (590,)\n"
          ]
        }
      ],
      "source": [
        "### When using train_test_split it applies the scaler to X_train only\n",
        "start_feature = train.columns.get_loc('10min_RSI_3_diff')\n",
        "train_features = [col for col in train.columns[start_feature:] if col != 'label']\n",
        "\n",
        "X = train.loc[:, train_features]\n",
        "y = train['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\",  X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\",  y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "bQ7NohxSqFxk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQ7NohxSqFxk",
        "outputId": "d7271eed-d26c-4d25-d12e-a483657522bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    719\n",
            "0    656\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "1    343\n",
            "0    247\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "G_0TrSpzsRuA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_0TrSpzsRuA",
        "outputId": "e4588200-4f83-4273-dc17-8859499c9b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10min_RSI_3_diff  10min_RSI_3  10min_Close_Kal_300  Close_Kal_300  10min_slope_div_300_3_diff  slope_angle_300_6  MFI_7_diff  10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_3  slope_div_300_6 - slope_div_300_9  10min_slope_signal_600_6  slope_lin_reg_signal_300_3  slope_lin_reg_600_9_diff  slope_angle_600_9_diff  slope_signal_300_6_diff  10min_slope_signal_900_9_diff  Kal_600_minus_Kal_900  10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9  10min_slope_angle_600_3_diff  10min_slope_lin_reg_signal_600_6  10min_MFI_7_diff  10min_RSI_7  10min_slope_lin_reg_signal_900_3_diff  10min_slope_lin_reg_signal_300_9  10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_9  MFI_3_diff  10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_3  10min_slope_angle_300_3 - slope_angle_900_6  slope_signal_600_6 - slope_signal_900_6  10min_slope_angle_900_9_diff  10min_slope_angle_300_9_diff  slope_signal_600_3 - slope_signal_900_3  slope_signal_900_6  slope_signal_600_3 - slope_signal_600_9  10min_slope_signal_600_3 - slope_signal_900_6  slope_signal_900_3_diff  10min_slope_signal_300_3 - slope_signal_900_6  10min_slope_signal_600_9 - slope_signal_900_6  10min_slope_angle_300_3_diff  10min_slope_signal_300_9  slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3  10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9  slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9  slope_div_300_3 - slope_div_900_6  slope_signal_300_3 - slope_signal_600_9  slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6  10min_slope_signal_300_6 - slope_signal_300_9  OBV_diff   slope_signal_300_6 - slope_signal_600_9  10min_slope_signal_600_3 - slope_signal_900_3  10min_Kal_change_600  10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6  10min_slope_lin_reg_signal_600_3  slope_lin_reg_300_3 - slope_lin_reg_600_9  slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6  10min_slope_lin_reg_signal_900_6  10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6  slope_signal_300_9 - slope_signal_600_6  10min_slope_signal_300_6_diff  10min_slope_lin_reg_signal_600_9_diff  slope_lin_reg_signal_900_9_diff  slope_signal_300_3 - slope_signal_300_9  slope_signal_300_6 - slope_signal_600_6  MFI_14_diff  RSI_7      10min_slope_signal_300_3 - slope_signal_900_3  slope_lin_reg_300_6_diff  10min_slope_signal_300_6 - slope_signal_900_6  slope_angle_300_6_diff  10min_slope_angle_600_6_diff  10min_slope_lin_reg_signal_600_6_diff  10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_9  10min_slope_signal_600_9_diff  slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_9  slope_signal_300_9_diff  slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_6  slope_angle_600_6 - slope_angle_900_6  10min_slope_lin_reg_signal_900_9  slope_angle_300_3_diff  10min_slope_signal_300_3 - slope_signal_300_9  10min_slope_signal_600_6 - slope_signal_900_6  slope_div_600_3  10min_slope_signal_300_3 - slope_signal_600_9  10min_slope_angle_600_6 - slope_angle_900_9  10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_6  10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3  10min_slope_signal_600_3  slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9  slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3  slope_angle_600_6 - slope_angle_600_9  10min_MFI_3_diff  10min_slope_lin_reg_300_3 - slope_lin_reg_600_9  slope_angle_300_6 - slope_angle_600_6  10min_Kal_change_300  slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_9  slope_lin_reg_signal_600_6  10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_3  10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_900_3  slope_signal_300_3 - slope_signal_600_3  10min_MFI_14_diff  10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_6  10min_slope_lin_reg_signal_600_3_diff  slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_9  slope_signal_600_3 - slope_signal_900_9  10min_slope_angle_600_3 - slope_angle_600_6  slope_lin_reg_signal_300_6 - slope_lin_reg_signal_300_9  10min_OBV_diff  10min_MFI_7 - MFI_14  10min_slope_signal_300_3 - slope_signal_300_6  10min_slope_signal_300_3_diff  slope_angle_300_6 - slope_angle_300_9  slope_angle_900_6  slope_angle_300_3 - slope_angle_300_6  10min_slope_signal_300_3 - slope_signal_600_3  slope_signal_300_3 - slope_signal_900_6  slope_lin_reg_300_3 - slope_lin_reg_600_3  10min_slope_signal_900_9  10min_slope_signal_300_6 - slope_signal_600_9  10min_slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9  slope_angle_300_3 - slope_angle_600_9  slope_div_300_6_diff  10min_slope_signal_300_9_diff  slope_lin_reg_300_3_diff  slope_lin_reg_signal_300_6  slope_lin_reg_signal_900_9  slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_6  10min_slope_angle_900_6_diff  slope_lin_reg_signal_300_6 - slope_lin_reg_signal_600_3  slope_angle_300_6 - slope_angle_600_9  slope_signal_300_3 - slope_signal_900_9  10min_slope_angle_300_6 - slope_angle_300_9  10min_slope_signal_300_6  slope_lin_reg_signal_300_3 - slope_lin_reg_signal_300_6  10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_600_3  10min_slope_angle_300_3 - slope_angle_600_3  10min_slope_angle_600_9_diff  slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9  OBV        slope_lin_reg_signal_600_3_diff  10min_slope_lin_reg_signal_300_6 - slope_lin_reg_signal_900_6  10min_slope_signal_300_9 - slope_signal_600_6  slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6  slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_9  slope_signal_600_9 - slope_signal_900_9  slope_angle_900_9_diff  10min_Kal_300  10min_MFI_7  slope_angle_300_9_diff  10min_MFI_3  10min_slope_angle_300_6_diff  slope_div_300_6 - slope_div_600_9  slope_lin_reg_signal_600_6 - slope_lin_reg_signal_900_6  10min_slope_lin_reg_signal_900_6_diff  slope_signal_600_3  slope_signal_300_3 - slope_signal_600_6  10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_3  10min_slope_angle_600_6 - slope_angle_600_9  slope_signal_600_6 - slope_signal_600_9  10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_6  10min_slope_signal_300_3  RSI_3_diff  10min_RSI_3 - RSI_7  10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_6  Kal_300    10min_slope_angle_300_3 - slope_angle_300_9  10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_600_9  slope_angle_600_6  10min_slope_signal_600_9 - slope_signal_900_9  slope_signal_600_6 - slope_signal_900_9  10min_slope_angle_300_3 - slope_angle_900_9  slope_signal_600_3 - slope_signal_900_6  slope_lin_reg_signal_300_9  slope_lin_reg_signal_600_6 - slope_lin_reg_signal_600_9  10min_slope_lin_reg_signal_900_9_diff  10min_MFI_14  10min_slope_signal_900_3_diff  10min_slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_9  10min_slope_lin_reg_signal_600_9  MFI_3 - MFI_7  slope_angle_600_9 - slope_angle_900_9  slope_signal_300_3 - slope_signal_900_3  RSI_14     Kal_change_300  slope_signal_300_6 - slope_signal_300_9  10min_slope_lin_reg_signal_900_3  10min_slope_angle_300_3 - slope_angle_300_6  slope_signal_900_6 - slope_signal_900_9  10min_slope_lin_reg_signal_300_9 - slope_lin_reg_signal_900_3  slope_lin_reg_signal_600_3  slope_signal_900_9_diff  10min_slope_div_300_3 - slope_div_900_6  10min_slope_signal_900_6  10min_slope_signal_900_6 - slope_signal_900_9  slope_signal_300_6 - slope_signal_900_6  slope_signal_600_6  10min_slope_div_300_3 - slope_div_600_6  slope_angle_900_6_diff  slope_div_300_3  10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_6  10min_slope_angle_300_6 - slope_angle_600_6  10min_slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_6  slope_lin_reg_600_6_diff  slope_lin_reg_signal_900_6  10min_slope_signal_300_6 - slope_signal_900_9  10min_slope_lin_reg_signal_300_9_diff  10min_RSI_7 - RSI_14  10min_slope_signal_600_9  10min_slope_signal_300_6 - slope_signal_600_6  slope_signal_600_9  slope_signal_600_9 - slope_signal_900_6  slope_signal_600_3 - slope_signal_600_6  10min_slope_angle_600_9 - slope_angle_900_9  10min_OBV  slope_lin_reg_signal_900_3  slope_angle_300_9 - slope_angle_600_9  10min_slope_signal_600_3 - slope_signal_600_6  slope_div_300_6  10min_slope_lin_reg_signal_600_3 - slope_lin_reg_signal_900_9  slope_lin_reg_signal_900_3 - slope_lin_reg_signal_900_6  10min_slope_angle_300_3 - slope_angle_600_9  slope_signal_300_6 - slope_signal_600_3  slope_signal_900_6_diff  slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_9  10min_slope_signal_600_6 - slope_signal_600_9  slope_angle_600_3 - slope_angle_900_3  10min_slope_signal_300_3 - slope_signal_900_9  10min_slope_div_300_3 - slope_div_300_6  slope_signal_600_9_diff  slope_angle_300_3 - slope_angle_600_6  10min_slope_lin_reg_signal_300_3 - slope_lin_reg_signal_600_3  slope_lin_reg_signal_600_9 - slope_lin_reg_signal_900_9  10min_slope_signal_600_6_diff  slope_signal_300_3_diff  slope_signal_300_9 - slope_signal_600_9  10min_slope_angle_600_6 - slope_angle_900_6\n",
            " 3.601864          1.062868     0.869037             2.041124       0.700060                   -1.449602           1.257630   -0.021772                                                       0.401295                           0.968008                 -1.209045                   -0.377193                  0.189934               -0.012669                 2.419285                      -1.026124              -0.059719                                                       0.263742                     -0.977742                          1.164808          0.497351     0.011923                              -1.069946                          0.014108                                                      -0.013153    0.013575                                                       0.483455                                     0.023518                                 0.006583                     -0.004101                      0.048602                                 1.038228           -0.036448                                 0.044654                                       0.000000                 0.065630                                      -1.799531                                       0.221870                     -0.968008                 -2.068077                                                 0.024945                                                       2.425762                                                 0.023485                          -0.123095                                -2.345325                                                 2.047499                                       1.059651  -0.099235                                -0.152561                                       0.177965              0.063214                                                      -0.997497                          1.148212                                  -2.582066                                                -1.027884                         -0.035289                                                      -0.026669                                 2.493742                       0.013099                               0.000000                        -0.052164                                -0.063214                                 1.363984     0.728653  -0.089030                                      -0.599876                  0.092074                                       0.321081                0.044146                      0.013099                               0.089030                                                       0.012669                      -0.086269                                                 0.000000                 2.900174                                                -1.754089                              -1.017650                          2.480515                1.563770                                       0.037729                                       0.253294         1.689821                                      -0.043441                                     0.038032                                                      -0.013099                                                       0.987571                  2.373694                                                -2.795299                                                 0.537411                               1.232655         -0.068292                                        -0.446655                              -0.107421             -0.152561                                                -1.148457                   -0.019566                                                      -0.013099                                                      -0.142500                                -0.114986          -0.104937                                                       0.012669                              -0.077189                                                -0.039155                                 0.305251                                    -0.051389                                                 0.956824       -1.182798             -0.020366                                       2.176717                       0.362305                              -0.734705           2.139905                               0.017109                                      -0.115957                                 0.515474                                   0.968008                  2.330886                                       0.053395                                                       1.774922                               1.443501              0.013099                      -0.505074                 -1.234499                   -1.113982                   -0.114008                                                 0.057125                     -2.723134                                                 0.507226                              -0.135049                                -0.008540                                     1.017650                  0.037729                                                -0.072207                                                      -0.005968                                    -0.003462                      2.192220                                                 0.513233   2.443574                         0.025764                                                      -1.740339                                      -2.546518                                                -0.058789                                                 0.000000                                 0.296079                0.169850      -1.682679     0.132857               -0.634306     0.028455                      0.138444                          -3.810608                                                 0.012669                               1.038228           -0.118712                                -0.029643                                                      -0.044183                                    -0.035790                                 0.054717                                                       0.997497                  1.059734    1.431620            -0.039932                                                       0.497381   0.165288                                     0.021772                                                      -1.177348          -3.464823                                      -0.039324                                 0.244624                                     0.000000                                -1.196591                   -0.017109                                                 0.013099                              -1.210054      2.092510                       0.031559                                                      -1.017650                          0.133937      -0.274090                              -0.063469                                 0.138578   0.599774       -0.010515                                -0.987571                          0.275774                                    -0.047075                                -0.073042                                                       0.840152                   -0.013099                 0.209374                                 0.948809                 -0.021272                                      -0.040757                                 1.048683            0.028363                                 1.488679               -0.281616        -0.030089                                                       0.095591                                     0.011596                                                      -0.134647                  0.884186                    0.065630                                       0.014108                               0.633301             -0.987571                  0.085851                                       1.080761            0.042572                                -0.011295                                 0.022358                                    -0.373076   0.884186                   -0.106255                               0.019200                                      -0.955105         0.022890                                                       0.000000                                                 0.207744                                    -0.028038                                -0.012669                -0.090598                                                 2.040101                                      -1.407626                               0.029078                                      -0.115402                                -0.013099                 2.135222                               0.000000                                                      -0.040757                                                 2.575526                      -0.012279                -0.080236                                 0.008459                                      1\n",
            "-4.024021         -2.126550    -3.167682            -3.905664      -2.270832                    0.832027          -1.834788    0.042572                                                       0.535039                          -1.017650                  0.723936                    1.229954                 -0.132088               -2.575526                -2.575526                       0.884119               0.047075                                                      -1.885366                      0.848833                         -2.556186         -2.417543     0.000000                               0.884186                          0.024200                                                      -1.588468    0.024945                                                      -0.511687                                     0.019566                                -0.074587                     -0.070557                      0.037729                                -0.968008            0.007837                                -0.077340                                       0.009877                -0.111189                                      -0.129474                                      -0.900524                     -0.958364                  0.063931                                                -0.100252                                                      -0.095454                                                -0.602046                          -0.042495                                -0.083286                                                -0.081440                                      -1.507036  -0.048443                                -0.075620                                      -2.078838             -0.039324                                                       0.805995                         -0.039680                                  -0.026669                                                 0.857575                         -0.081175                                                       0.009183                                -2.575526                       0.000000                              -0.014108                        -0.024121                                -0.018215                                -2.422986    -1.833883  -0.075024                                       1.137817                 -0.072771                                      -0.141631               -0.200027                      0.000000                              -0.118712                                                      -2.766559                      -0.061508                                                -2.521180                -0.191617                                                -0.040201                               0.848833                         -0.742824               -0.098286                                      -0.085851                                      -0.068452         0.044654                                       0.014428                                    -0.072771                                                       0.086269                                                      -1.038228                 -0.151337                                                -0.051389                                                 0.108468                              -2.229043         -0.299331                                        -0.132278                              -1.534952             -0.163951                                                 0.840152                   -0.051389                                                      -0.034808                                                      -0.113840                                -2.410064           0.047075                                                       0.000000                              -0.159727                                                 0.016863                                -1.369826                                    -0.017109                                                -1.621975       -0.268335             -0.032286                                      -2.351123                       0.035094                               0.832896          -0.434876                              -0.033268                                      -0.011596                                -0.719136                                  -1.091702                  0.092074                                      -0.051389                                                      -0.288477                              -1.687232             -2.879525                       1.107579                  0.756260                    0.805995                   -0.179156                                                -0.326249                      0.014108                                                 0.037800                              -0.037072                                 0.006930                                    -1.027884                 -0.081718                                                 0.099633                                                       1.185517                                    -0.060958                     -0.011923                                                 1.740284   0.000000                         0.012279                                                       0.057687                                       0.114766                                                 0.063214                                                 0.019566                                -0.180324                1.846286       0.051614    -0.095083               -0.419094    -0.173192                      1.544283                           0.165107                                                 0.000000                              -0.920648           -0.022310                                 0.053860                                                      -0.046492                                    -0.032286                                -0.086712                                                      -1.059255                 -1.690055   -1.146852             0.031559                                                       1.990792  -0.402681                                    -0.107252                                                       0.839925          -0.021272                                      -0.022890                                -0.544787                                     0.055162                                 0.764438                   -0.015394                                                 0.000000                               0.421018     -1.994994                      -0.022890                                                       0.875250                         -0.935496       0.007119                              -0.053395                                -1.769598  -1.653523       -0.021272                                 0.831529                         -0.614224                                    -0.031559                                 0.055656                                                       0.748123                   -2.575526                -0.163209                                -0.968008                  0.125784                                       0.000000                                -0.958364           -0.674516                                -0.215002                0.294716        -0.063469                                                      -0.011583                                     0.026669                                                       0.982817                  0.772658                    0.072771                                       0.000000                              -1.874659             -1.102774                 -0.017109                                      -0.929953            0.039155                                 0.040757                                 0.108114                                     1.787405   0.797589                   -0.010685                              -0.020366                                       0.752148        -0.068029                                                       0.044165                                                -0.554820                                    -0.045201                                -2.419285                -0.200392                                                 0.091924                                       2.813557                               0.035790                                      -0.461180                                -2.766559                -0.638479                               0.000000                                                       0.091440                                                -2.351123                      -2.092510                -0.030089                                 0.204493                                      1\n",
            "-3.784841         -1.481827    -2.496261            -4.577873      -1.724686                    1.207721          -1.535593   -0.011016                                                      -1.013331                          -0.939339                  1.102774                    0.651351                 -0.377145                0.013099                -2.606682                       2.061047              -0.094466                                                      -0.577306                      0.958364                         -1.622170         -1.381750     0.000000                               0.939339                         -0.048443                                                      -1.327752   -0.039324                                                      -0.497169                                     0.075620                                -0.099568                     -0.052973                      0.044654                                -0.948809            0.083415                                 0.019200                                       0.000000                 0.051511                                       0.027559                                      -0.562186                     -0.987571                  1.956660                                                -0.061508                                                      -2.632880                                                 0.679846                           0.045962                                 2.140625                                                 0.104566                                      -2.345384   0.111189                                -0.021272                                      -1.261889             -0.042358                                                       0.977742                         -1.234394                                   2.126670                                                 1.017650                          0.031559                                                      -0.124601                                -2.247735                       0.000000                               0.000000                         0.045201                                -0.070711                                -0.343435    -1.338937   0.030089                                       0.894962                  0.080236                                      -0.816615               -0.099905                      0.000000                               0.000000                                                      -2.807521                       0.033903                                                 0.000000                -3.063315                                                 2.738217                               1.017650                         -4.462410                0.076647                                       0.026669                                      -0.791745         0.017636                                       0.005773                                    -0.094466                                                       0.000000                                                      -0.929953                 -2.311907                                                 3.073310                                                -2.588932                              -1.732805          0.067769                                         2.962875                              -0.789179              0.046225                                                 1.048683                   -0.019566                                                      -0.063469                                                      -0.098286                                -1.766008          -0.024200                                                       0.000000                               0.026669                                                 0.034749                                -0.401623                                     0.019566                                                -2.028488        0.729480             -0.009183                                      -2.047499                      -0.702530                              -0.829488          -3.041692                               0.051389                                      -0.041635                                -0.781100                                  -0.875250                  0.034808                                      -0.044165                                                      -2.746935                              -3.127179             -2.927069                       0.637788                  1.113982                    1.069946                    0.080236                                                -0.110361                      2.602237                                                -0.590511                              -0.009511                                 0.083553                                    -0.893192                 -0.017109                                                -0.047075                                                       0.052823                                    -0.086841                     -2.205951                                                 0.355750  -2.443574                        -0.045817                                                      -0.043785                                       2.285737                                                -0.028807                                                -0.100252                                -0.832384               -0.036087       1.268698    -0.211484                0.340179    -0.102842                     -0.328991                           3.440290                                                 0.000000                              -0.939339           -0.078492                                 0.000000                                                       0.035439                                     0.132135                                -0.053395                                                      -0.902270                 -0.807482   -1.116922            -0.083488                                                      -0.564205  -0.249297                                    -0.012279                                                      -0.095883          -0.106943                                       0.073803                                -0.417126                                     0.009877                                 1.102774                   -0.040757                                                 0.000000                               1.009622     -1.892727                      -0.033903                                                       0.987571                         -0.950998       0.955184                              -0.046225                                -1.149213  -2.223216        0.102182                                 0.987571                         -0.480282                                     0.029078                                -0.050446                                                      -0.939339                    0.011016                -0.565939                                -0.948809                 -0.078492                                       0.000000                                -0.911421           -0.437710                                -4.701444               -0.039174        -0.026669                                                      -0.006674                                    -0.035790                                                       0.388559                 -0.893192                   -0.025764                                       0.000000                              -1.127251             -0.920648                  0.077189                                      -1.038228           -0.082929                                -0.027103                                -0.067611                                     1.084762  -0.884186                    0.305038                               0.009343                                       0.786948        -0.049937                                                       0.013575                                                -0.350802                                    -0.008749                                 0.011295                 0.025764                                                -0.019566                                       0.513026                              -0.027103                                      -0.018223                                 0.012279                -0.597607                              -0.066648                                                       0.018215                                                -2.307693                       0.000000                 0.000000                                -0.013366                                      1\n",
            "-3.649399         -1.812616    -1.288118            -1.284330      -0.872733                    0.037048          -1.602548    0.032286                                                       0.373958                          -1.007522                  0.814453                    0.371913                 -0.267242               -2.521180                 0.000000                      -0.056375               2.789178                                                      -2.511301                      0.866380                         -0.333848         -1.514433    -0.011923                               0.884186                          3.063315                                                      -0.115810    0.092074                                                       2.681241                                    -0.019566                                -3.029703                     -0.155391                     -0.054717                                -0.948809           -0.047369                                -0.019200                                      -2.005274                -0.125784                                       0.028544                                      -1.675202                     -0.920648                  0.056563                                                 2.728669                                                      -0.103504                                                -0.610241                          -0.081549                                -0.068816                                                -0.053860                                      -1.238334   0.012669                                -0.058789                                      -0.912915             -0.044165                                                       0.840152                          0.373504                                  -0.072771                                                 0.831529                         -0.048602                                                       0.009343                                 0.000000                       0.000000                               0.000000                        -0.087152                                 0.016184                                -0.198112    -1.359485  -0.166978                                       0.164649                  0.026669                                      -0.732817               -2.496365                      2.807521                               0.000000                                                       0.000000                      -0.068816                                                -2.879525                -0.046225                                                -0.353449                              -1.184310                         -1.349272               -0.165975                                      -0.049937                                      -0.022528        -0.139073                                      -0.558376                                     0.068816                                                      -0.012279                                                      -1.007522                 -0.083286                                                 0.015394                                                 0.578685                              -1.373688         -0.298746                                        -1.339897                              -0.586429             -0.085851                                                 0.831529                    0.081718                                                       0.111189                                                      -0.046225                                -0.338063           0.023518                                                      -0.012669                              -0.073737                                                -0.016863                                -0.147217                                     0.000000                                                -1.365438       -0.533455             -0.135614                                      -2.288415                       1.388580                               0.626034          -0.026430                              -0.168608                                      -0.109490                                -0.058913                                  -0.948809                 -0.011295                                       2.927069                                                      -0.400545                              -0.247043              0.000000                       0.187743                  0.814453                    0.866380                   -0.035289                                                -1.401249                      0.014108                                                -0.898977                              -0.049444                                -0.568605                                    -0.968008                  0.000000                                                 0.052646                                                       2.362015                                    -0.630587                     -0.077499                                                 0.406040   0.000000                         0.000000                                                       0.081549                                      -0.012279                                                -0.070711                                                 0.081718                                -0.402532                1.350739      -0.051852    -0.062779               -0.796705    -0.508467                     -0.153010                          -0.066648                                                 2.521180                              -1.017650           -0.099633                                -2.003709                                                      -2.126221                                     0.000000                                 0.016184                                                      -1.113982                 -2.165845   -1.524680             0.058789                                                       0.765007  -1.138067                                     2.373694                                                       0.542732          -0.018215                                       0.044654                                 0.841393                                    -0.067977                                 0.814453                   -0.051389                                                 0.000000                               0.550997     -2.036132                       2.188051                                                      -1.136819                         -0.151768      -1.125327                              -0.070711                                -0.908032  -0.645530        0.000000                                 0.805995                         -1.184849                                     0.050446                                 0.084382                                                       0.805995                   -2.230471                 0.979923                                -0.987571                 -0.040757                                       0.000000                                -0.958364            0.576027                                -0.593093               -0.116465         0.027676                                                       3.026793                                    -2.264984                                                       0.344028                  0.866380                   -0.022890                                      -0.016184                              -1.501066             -0.958364                  0.063214                                      -0.958364           -0.009343                                -0.054717                                 3.875144                                     1.869192   0.814453                   -2.067363                               0.000000                                      -0.155395         2.575526                                                      -0.090598                                                -0.911748                                     0.061356                                -2.443574                -0.081175                                                -0.050446                                       0.402823                              -0.161682                                      -0.306956                                -2.665923                -1.650801                               0.068029                                                      -0.018215                                                 0.000000                      -2.005274                 0.018215                                 1.483644                                      1\n",
            "-3.253401         -0.569609    -0.700829            -0.915213      -0.320915                    1.187245          -1.635046   -0.065442                                                       0.110869                          -1.017650                  1.113982                    0.697635                 -0.171759               -2.521180                -0.012279                       0.264145              -0.070711                                                      -0.193909                      1.059255                         -2.114599          0.375193    -0.011923                               0.968008                         -0.068029                                                      -1.247588    0.025764                                                      -0.595504                                    -0.106943                                 0.034845                     -0.022951                     -0.063931                                -1.080761            0.015975                                -0.030880                                       0.010289                -0.094466                                       1.866574                                      -0.185489                      0.958364                  0.050446                                                -0.100252                                                       0.013575                                                -0.061032                          -0.042495                                 0.047075                                                -2.329024                                      -0.641566  -0.107928                                 0.000000                                       0.314629             -0.046225                                                       0.997497                         -0.269767                                   0.012279                                                 1.069946                         -0.100252                                                       0.103316                                -2.766559                      -0.014709                               0.000000                        -0.040757                                 0.033268                                -2.053755    -0.160399  -0.065630                                       0.895099                  0.000000                                      -0.141479               -0.059651                     -0.014108                              -0.013575                                                      -0.013099                       0.107928                                                -2.419285                -0.015394                                                 0.246888                               1.027884                         -0.775873               -1.804586                                      -0.054717                                       0.452107        -1.980578                                      -0.128884                                    -0.140730                                                      -0.026669                                                      -1.017650                 -0.059719                                                 0.108376                                                -0.363549                              -1.837357          0.269511                                         0.205234                               0.520414             -0.014709                                                 1.048683                   -0.070711                                                      -0.100252                                                      -0.138247                                -1.849471          -0.104937                                                      -0.013575                               0.046225                                                 0.026255                                -0.308556                                    -0.070711                                                -0.773522        0.820319             -0.085378                                      -2.176717                      -0.321738                               1.038269          -0.907941                              -0.085851                                       0.012279                                -0.451726                                   1.017650                 -2.395797                                       0.031559                                                      -0.891721                              -0.336802             -0.013099                       0.786819                  1.080761                    1.027884                    0.044165                                                -0.077361                      0.053395                                                -0.420471                              -0.037072                                -0.167729                                    -0.987571                  0.063931                                                -0.033903                                                      -0.035911                                     0.027827                      0.011596                                                -0.211233   0.000000                        -0.133547                                                       1.937062                                       0.024200                                                 0.037729                                                 0.016184                                -0.240943               -0.782011       1.134073    -0.107632                0.012207    -0.064373                      0.291342                          -0.044654                                                -0.013575                              -0.997497            0.072771                                 0.000000                                                      -0.062531                                    -0.113908                                -0.138247                                                      -1.069946                 -3.016958   -1.801669            -0.104566                                                       0.049198  -0.354212                                    -0.051579                                                       1.109122          -0.058789                                      -0.112227                                -0.477987                                     0.089578                                 1.125328                   -0.055416                                                -0.013575                               0.757845     -1.994994                       0.011596                                                       1.038228                         -2.013315       0.317437                              -0.145500                                 0.655651   0.213068       -0.099633                                 1.038228                         -0.400251                                    -0.049444                                -0.066724                                                       1.038228                    0.000000                -0.151580                                -0.987571                 -2.113540                                      -0.039324                                -1.136819            0.083532                                -0.253754                0.688086        -0.139677                                                      -0.026198                                    -0.039324                                                       0.721465                  1.069946                   -2.632880                                      -0.017109                              -0.627028              0.987571                  0.044165                                      -1.017650            0.055656                                 0.137991                                -0.108394                                    -0.500984   1.038228                    0.049158                               0.000000                                       0.901965        -0.039324                                                      -0.046225                                                -0.386514                                    -0.099836                                -2.443574                 0.027676                                                -2.162139                                       1.085615                              -2.207495                                       0.101755                                 0.000000                -0.951755                              -0.063214                                                       0.113840                                                -2.351123                       0.011016                 0.000000                                -0.181460                                      1\n",
            "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ..\n",
            "-2.732324         -1.195422    -0.811474            -1.141591      -0.677582                    0.671197          -1.689132    0.022310                                                      -0.290361                          -0.997497                  0.715944                   -0.052984                 -0.112957                0.000000                -2.351123                       0.525488              -0.013575                                                      -0.345375                      0.958364                         -1.114543         -0.295195     0.000000                               0.977742                         -0.095060                                                      -1.207379    0.073737                                                      -0.514304                                     0.035289                                -0.036239                     -0.015866                     -0.106943                                -1.038228           -0.078984                                 0.070711                                       0.011016                 0.051511                                       0.045962                                      -0.267196                     -0.958364                  2.420483                                                -0.207992                                                      -2.859471                                                -0.161431                          -0.058789                                 2.418005                                                 0.025764                                      -0.736118  -0.111350                                -0.040757                                      -0.278478             -0.091440                                                       0.911421                         -0.442728                                   2.178574                                                 0.958364                         -0.091440                                                       0.019566                                -2.575526                      -0.016184                               0.000000                         0.016863                                 0.033268                                -1.506678    -1.828055  -0.048602                                      -0.065514                  0.113908                                      -0.310012               -0.060361                     -0.014709                              -0.139677                                                      -2.575526                      -0.132294                                                 0.012669                -3.324990                                                 0.953146                               0.987571                         -1.909115               -0.034234                                       0.077189                                      -0.463988         0.000000                                       0.131803                                    -0.107252                                                       0.024945                                                      -0.977742                 -2.835738                                                 3.124381                                                -0.310026                              -1.388024          0.001019                                         0.240127                              -0.070909             -0.114008                                                 0.731963                    0.000000                                                      -0.040757                                                       0.046225                                -1.034939           0.025764                                                       0.000000                              -0.095060                                                -0.037072                                -0.334443                                    -0.021272                                                -0.545356        1.225492             -0.055656                                       0.000000                      -0.218296                               0.237953          -1.527816                              -0.035289                                       0.068816                                -0.102731                                  -1.007522                  0.077499                                      -0.128536                                                      -1.265616                              -0.750169             -2.575526                      -0.161424                  0.684277                    0.780922                   -0.086712                                                -0.078594                      2.594297                                                -0.180484                              -0.010077                                 0.046450                                    -0.939339                  0.089578                                                 0.077340                                                      -0.040465                                    -0.028938                     -2.795299                                                 1.333488  -2.701519                        -0.040757                                                       0.039155                                       2.485798                                                -0.123095                                                 0.091440                                -0.165121                2.256867       1.694804    -0.076865                0.471396    -0.029431                     -0.428797                           3.526370                                                -0.013575                              -1.007522            0.043576                                 0.146719                                                       0.109292                                    -0.118381                                -0.091440                                                      -0.997497                 -1.276071   -1.970271             0.022310                                                       1.529411  -0.130357                                    -0.168341                                                       0.536483           0.018215                                      -0.068029                                -0.316089                                     0.030880                                 0.692152                   -0.016184                                                -0.014709                               1.188677      0.000000                      -0.111350                                                       1.027884                         -2.653133       0.085671                              -0.026669                                -1.052360  -0.693730        0.000000                                 0.911421                         -0.240246                                    -0.079311                                 0.070711                                                      -1.359359                    0.011923                -0.243584                                -1.048683                 -0.038422                                       0.049937                                -1.017650           -0.195934                                -1.117740               -0.285499        -0.121187                                                      -0.191436                                     0.099235                                                      -0.196923                 -1.234499                    0.089030                                       0.000000                              -1.698129             -0.997497                  0.080236                                      -0.920648            0.123095                                 0.009511                                -0.023290                                     2.375633  -1.301610                    0.081339                               0.018526                                      -0.013953        -0.127196                                                      -0.106943                                                -0.256528                                     0.009031                                 0.000000                -0.044165                                                 0.000000                                       1.255261                               0.009877                                      -0.068440                                 0.013099                -1.545896                              -0.046225                                                      -0.091440                                                -2.288415                       0.011016                -0.121187                                -0.070135                                      1\n",
            "-2.751772         -0.971387    -0.784185            -2.123052      -1.020671                    0.706266          -1.474847    0.000000                                                      -1.897452                           1.038228                  0.676428                   -0.765165                 -0.161370                0.000000                -0.011923                       1.857033              -0.083750                                                      -0.158379                      0.822963                         -0.432573         -0.434853    -0.012279                               0.848833                         -0.114766                                                      -0.129464   -0.014709                                                      -0.295674                                    -0.048602                                -0.027074                      0.009590                      0.040757                                -1.027884            0.031962                                -2.027785                                       0.010077                -2.443574                                      -0.083488                                      -0.157518                      0.997497                  0.156896                                                -0.046225                                                      -0.115957                                                 1.937095                           0.044476                                 2.728669                                                 0.081440                                      -2.095793  -0.051579                                 0.019566                                       0.000300             -0.063214                                                       0.805995                         -1.949508                                   2.582266                                                 0.866380                         -0.040757                                                       0.101532                                -0.015394                      -0.017109                               0.000000                         0.040757                                 0.120621                                -0.377185    -1.261481  -0.013099                                      -0.205757                  0.030089                                      -0.330828               -0.012170                     -0.014709                               0.017109                                                      -0.013575                       2.475299                                                 0.000000                -0.037729                                                 6.735027                               0.911421                         -2.305313               -1.686628                                      -0.023518                                      -1.006856        -1.857623                                      -0.009563                                    -0.012669                                                       0.042358                                                      -0.920648                 -0.157086                                                 3.702537                                                -1.723215                              -1.755231          0.210206                                         1.887557                               0.245512              3.392288                                                -1.488179                   -0.051389                                                       0.036860                                                       0.017109                                -1.681912           0.039324                                                      -0.014108                               3.052708                                                 0.052164                                -0.141256                                    -0.089578                                                -1.698444        1.142281             -2.113540                                      -2.493742                      -0.307474                              -1.485655          -1.939356                              -0.035289                                       0.152495                                -0.399492                                   1.027884                  0.139677                                      -0.114008                                                      -1.925489                              -2.404255             -0.015394                      -0.201225                  0.645250                   -1.389774                    3.374534                                                -0.024429                      3.220549                                                -0.499332                               0.066724                                 0.088323                                     1.069946                  0.089578                                                 0.065630                                                      -0.036721                                    -0.014063                     -0.125673                                                 1.316909  -3.154362                        -0.048443                                                      -0.039932                                       0.114766                                                -0.113840                                                 0.031559                                -0.243047                1.704335       0.918352    -0.109345               -0.081649     0.016842                     -1.816826                           0.000000                                                -0.013575                              -0.911421            0.176853                                 0.072771                                                       0.025958                                    -0.119160                                -0.114008                                                      -0.939339                 -0.325911   -1.348366            -0.022310                                                       1.267900  -0.016172                                    -0.139881                                                       0.108777          -0.095060                                      -0.104937                                -0.210752                                     0.125784                                 0.676428                   -0.139881                                                -0.014709                               0.238537      0.000000                      -0.118712                                                       0.884186                         -0.511624       0.320121                               0.039324                                -1.130809  -1.156362       -0.043576                                 0.831529                         -0.115426                                    -0.065442                                 0.020804                                                      -1.523702                    0.000000                -1.447888                                 1.048683                  0.022310                                       0.047075                                -1.059255           -0.982903                                -5.140639               -0.339650         0.060261                                                      -0.077180                                     0.026669                                                      -0.855870                 -1.488179                    0.051579                                      -0.018215                              -0.874497              0.968008                  0.058789                                      -0.948809            0.075620                                 0.146896                                -0.061214                                     1.776958  -1.560780                    0.042799                              -1.882685                                       0.283681        -0.175423                                                      -0.070711                                                -0.144993                                    -0.070711                                 0.000000                 2.908494                                                 0.081440                                       0.905962                              -2.226287                                       0.116908                                 0.000000                -0.602479                               0.106401                                                       0.058789                                                -0.014108                       0.000000                 0.000000                                -0.073353                                      1\n",
            "-2.782466         -0.252404    -0.722662            -1.688523      -0.477721                    1.039189          -0.719557    0.085378                                                       0.073924                          -1.017650                  0.884186                    0.826631                 -0.048975                0.013099                 0.011016                       0.792215               0.061508                                                      -0.044426                      0.857575                         -1.536256          0.743736    -0.011596                               0.929953                          0.055416                                                      -1.541062    0.013099                                                      -0.024238                                     0.035289                                -0.035688                     -0.044613                      0.106943                                -0.968008            0.048500                                -0.030243                                       0.011016                -0.022310                                      -0.061356                                      -0.043844                     -1.080761                  2.176717                                                 0.121187                                                      -3.060754                                                -1.470587                           0.047075                                -0.065630                                                 1.965558                                      -0.366292  -0.031559                                -0.203613                                       0.690060             -0.014108                                                       0.893192                         -0.700658                                  -0.103575                                                 0.857575                          0.060261                                                      -0.020366                                 0.000000                      -0.014108                               0.000000                         0.046763                                -0.046225                                -1.110113    -0.009120  -0.114008                                       0.864904                  2.555547                                      -0.073488               -0.025253                     -0.013575                               0.026669                                                       0.011016                      -0.136317                                                 0.014709                -3.624736                                                -0.017683                               0.884186                         -0.655656                0.057105                                      -0.058789                                       0.044263         0.041312                                      -0.132217                                     0.121864                                                       0.036860                                                      -1.017650                 -2.630546                                                 2.739947                                                -0.071970                              -0.921479         -0.415778                                         0.026988                               1.149306             -0.166164                                                 0.893192                    0.106943                                                       0.145602                                                      -0.016184                                -0.174554           0.100252                                                      -0.013099                              -0.121187                                                 0.030880                                -0.129739                                    -0.018215                                                -0.473459       -0.929123             -1.848381                                      -2.192220                      -0.129177                               0.997811          -0.539067                               0.019566                                       0.065630                                -0.215790                                  -1.102774                  2.072401                                      -0.030089                                                      -0.468408                              -1.070634             -2.443574                       0.441695                  0.857575                    0.968008                   -0.063214                                                -0.025504                      2.559589                                                -0.105581                               0.025764                                -0.062765                                     0.911421                  0.063931                                                 0.042572                                                       0.110292                                    -0.038260                     -2.573518                                                -0.347684  -2.701519                         0.083750                                                      -0.054717                                       0.014108                                                -0.165107                                                -0.044654                                -0.055814                0.142503       0.606737    -0.047820               -0.267376    -0.029167                      0.164576                          -0.081718                                                -0.012279                              -0.911421            0.036860                                 0.031559                                                      -0.142899                                     0.012279                                 0.057687                                                      -1.007522                 -0.040946   -1.502056             0.083488                                                       2.332518  -0.150685                                     0.024200                                                       0.999912           0.070711                                      -0.013099                                -0.178662                                     0.075024                                 0.866380                   -0.091440                                                -0.013575                               1.945757     -2.092510                      -0.044654                                                       0.875250                         -2.069087      -0.025698                               0.051579                                 0.778301  -0.251575       -0.013099                                 0.848833                         -0.155817                                    -0.033903                                 0.085914                                                      -1.102774                    0.014709                 0.655800                                -0.987571                  0.107188                                      -0.011596                                -0.948809            0.451805                                -0.093396                0.506919         0.145500                                                       0.091200                                     0.023518                                                       0.469440                  0.929953                    2.330886                                      -0.014709                              -0.651880             -1.059255                  3.543923                                      -0.958364            0.010515                                 0.042572                                 0.066092                                    -1.197376  -1.059255                    0.074985                               0.000000                                       1.247895         0.012279                                                      -3.063315                                                -0.195054                                    -0.065538                                 0.011923                -0.090598                                                 0.038422                                       3.507993                               0.078984                                       0.344996                                 0.014709                -0.754154                               0.100252                                                      -0.063931                                                -2.443574                       0.011596                -0.013575                                 0.114664                                      1\n",
            "-2.798193         -0.900346    -0.504946            -1.421975      -0.343826                    0.149568          -0.768241    0.113652                                                      -0.273043                          -0.969538                  0.804071                   -0.001683                 -1.881575               -1.296041                -0.005048                       0.623676               0.070013                                                      -0.525393                      0.875685                         -1.652584         -0.495848     1.350744                               0.955775                          0.068545                                                      -1.335281    0.029788                                                      -0.505140                                    -0.057786                                 0.847390                      0.638559                      0.072094                                -0.992384           -0.012858                                -0.077571                                      -1.091344                -0.094883                                       1.944510                                      -0.398627                      1.039330                  0.011505                                                 0.000000                                                      -0.039715                                                 0.618334                          -0.070907                                -0.010615                                                -1.235714                                      -1.583028  -0.109587                                 0.035318                                      -0.092926             -0.029200                                                       0.865006                         -0.022968                                  -0.034173                                                 0.873910                         -0.021758                                                       0.045223                                -1.373471                       0.000000                              -0.007553                        -0.053747                                -0.050249                                -0.384540    -1.080058   0.020713                                       0.310189                  0.994529                                      -0.700742               -0.389314                      0.000000                              -0.028565                                                      -0.005364                      -0.060904                                                 0.006686                -0.048685                                                 0.376909                               0.901465                         -1.156435               -1.849616                                      -0.041615                                      -0.220207        -1.988959                                       0.293933                                     0.087318                                                       0.123662                                                      -1.019169                 -0.033972                                                 0.004328                                                 0.071204                              -0.896977         -0.230654                                         0.654347                               0.074648             -0.052828                                                 0.819879                    0.021921                                                       0.106073                                                      -0.118507                                -1.155508           0.103154                                                       0.000000                              -0.060891                                                -0.005122                                -0.508773                                     0.004970                                                -1.480180        0.808327             -0.932891                                      -2.150923                      -0.212786                              -0.205642           0.155568                              -0.000148                                      -0.045684                                -0.257354                                   1.030885                 -1.369591                                      -0.089820                                                       0.547167                              -0.681426             -0.006518                       0.153720                  0.788003                    0.822963                   -0.057710                                                -0.477276                     -0.009319                                                 0.741819                              -0.064596                                 0.331033                                    -0.156478                  0.034223                                                 0.114152                                                       0.188625                                     0.569144                     -0.014735                                                 1.231081  -0.012434                         0.110023                                                       1.842333                                       0.009285                                                 0.004807                                                 0.024932                                -1.662528                1.169860       0.419593    -1.501292               -0.080559    -0.296615                      0.517565                           0.007428                                                 0.000000                              -0.970856           -0.010548                                 0.095785                                                       0.110112                                    -0.069272                                -0.015305                                                      -1.028412                 -0.972447   -1.105252             0.097456                                                       1.447083  -0.055072                                    -0.102402                                                      -0.115870          -0.040661                                      -0.058460                                -0.158639                                     0.022952                                 0.786094                    0.007861                                                 0.000000                              -0.206443     -1.111746                      -0.054135                                                       0.938846                         -0.948287       0.895831                              -0.043303                                -0.819415  -0.708348       -0.076829                                 0.856273                         -0.413105                                    -0.021769                                 0.107926                                                       0.795119                    0.006686                -0.547342                                -0.947866                 -2.091653                                      -0.081773                                -1.027191           -0.469451                                -0.606097               -0.033741         0.092256                                                      -0.064428                                     0.087575                                                       0.242935                  0.811959                   -1.323368                                       0.000000                              -0.788988              1.010224                  1.320404                                      -0.955329            0.032787                                 0.053196                                 0.320245                                     1.386597   0.807600                    1.054718                              -0.050471                                       0.050295        -0.049006                                                      -0.002976                                                -0.270431                                    -0.075305                                -1.180585                -0.018164                                                -2.149537                                       1.677884                              -2.142869                                       0.041718                                 0.007080                 0.777244                               0.115115                                                      -0.011110                                                -2.354942                      -1.264031                -0.024667                                 0.150486                                      1\n",
            "-2.798599         -1.024694    -0.281125            -1.153556      -0.151111                    0.934733          -0.210165    0.089578                                                       0.475772                          -1.080761                  0.902270                    0.482909                 -0.127778               -2.288415                -2.351123                       0.281913               0.027676                                                      -0.339433                      0.939339                         -0.307200         -0.610481    -0.011923                               0.968008                          0.042358                                                      -1.227054    0.055416                                                      -0.174266                                    -0.018215                                -0.237033                      0.046612                     -0.049937                                -1.027884            0.034234                                -0.009689                                       0.010077                -0.091924                                       0.010077                                      -0.252711                      0.968008                  1.821172                                                -0.049937                                                       0.000000                                                -1.152016                           0.019200                                 0.063469                                                -2.826241                                      -1.222133  -0.075024                                -0.019566                                      -0.039583             -0.085851                                                       0.902270                         -0.412949                                   0.047075                                                 0.948809                         -0.075620                                                       0.029078                                -2.766559                      -0.017109                              -0.013099                         0.000000                                -0.085851                                -0.322431    -1.042690  -0.097230                                       0.325017                 -0.070711                                      -0.181355               -0.206966                     -0.015394                              -0.026669                                                      -2.665923                      -0.012279                                                -2.443574                 0.042358                                                 0.134793                               0.948809                         -1.918360               -1.847988                                      -0.120621                                      -0.259651        -0.091063                                      -0.236706                                     0.000000                                                       0.111350                                                      -1.017650                  0.000000                                                 0.016184                                                -0.048173                              -1.413918         -0.162331                                        -0.092555                               0.053951              0.000000                                                 0.866380                    0.000000                                                       0.063469                                                      -0.035289                                -0.191648           0.040757                                                      -0.012669                              -0.017109                                                 0.080236                                -0.233819                                     0.013575                                                -0.850814        1.001846             -0.019954                                      -2.079925                      -0.037639                               0.882404          -1.475145                              -0.108376                                       0.022310                                -0.436675                                  -1.027884                 -0.095454                                      -0.085851                                                      -1.212699                              -0.447376             -0.015394                       0.024151                  0.893192                    0.893192                    0.042358                                                -0.297807                      0.000000                                                -0.226380                               0.069303                                -0.161363                                    -1.069946                  0.015394                                                 0.081440                                                      -0.030097                                    -0.161907                     -1.994994                                                -1.856664  -0.011295                         0.036860                                                       2.111931                                       0.043576                                                -0.051389                                                 0.091440                                -0.167032                0.521576       1.196196    -0.075523                0.490961    -0.062299                      0.665483                           0.019566                                                -0.012279                              -0.987571            0.032286                                 0.097266                                                      -0.256445                                    -0.011016                                -0.081175                                                      -1.091702                 -0.756395   -1.162753             0.020804                                                       1.103125  -0.250946                                    -0.118712                                                       0.938385           0.063931                                       0.047075                                -0.445690                                     0.040757                                 0.884186                   -0.039324                                                -0.017109                               0.627669     -2.036132                      -0.061508                                                       0.987571                         -1.670869       0.015985                              -0.057687                                -0.977001  -0.618712       -0.089578                                 0.902270                         -0.228224                                     0.051511                                 0.069303                                                       0.893192                    0.000000                 0.176298                                -1.007522                  0.020366                                      -0.075024                                -1.038228            0.116009                                -0.277048               -0.069316         0.013099                                                      -0.076550                                     0.048443                                                       0.213498                  0.857575                   -0.048443                                      -0.017109                              -1.073877             -0.997497                  0.014709                                      -1.027884            0.000000                                 0.046763                                 0.153936                                    -0.974704  -1.113982                   -0.127153                               0.056644                                       0.324745        -0.077189                                                      -2.527387                                                -0.473767                                    -0.088514                                 0.000000                 0.011596                                                -0.089578                                       2.006053                              -0.062520                                       0.180801                                -2.351123                -1.744439                               0.077189                                                       0.000000                                                -2.351123                       0.000000                 0.030089                                 0.220940                                      1\n",
            "Name: count, Length: 1438, dtype: int64 \n",
            "\n",
            "label\n",
            "0    719\n",
            "1    719\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "### Rebalance Data frame due to the low number of class 1\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Now train your model on the resampled data\n",
        "print(X_train_resampled.value_counts(),'\\n')\n",
        "print(y_train_resampled.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "JQvYaSVZam-a",
      "metadata": {
        "id": "JQvYaSVZam-a"
      },
      "outputs": [],
      "source": [
        "# --------------- Classifier 1: XGBoost ------------------------------------------\n",
        "xgb = XGBClassifier(n_estimators=15, max_depth=3,\n",
        "                    random_state=42, eval_metric='logloss')\n",
        "\n",
        "# --------------- Classifier 2: Logistic Regression Classifier------------------------------------------\n",
        "lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# --------------- Classifier 3: AdaBoost Classifier ------------------------------------------\n",
        "ada = AdaBoostClassifier(n_estimators=15, random_state=42)\n",
        "\n",
        "# --------------- Classifier 4: SVM------------------------------------------\n",
        "svc = svm.SVC(kernel='rbf', probability=True, random_state=42)\n",
        "\n",
        "# Define a list to store the different models\n",
        "estimator = []\n",
        "estimator.append(('LR', lr))\n",
        "estimator.append(('XGB', xgb))\n",
        "estimator.append(('ada', ada))\n",
        "estimator.append(('SVC', svc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "9b68d18e",
      "metadata": {
        "id": "9b68d18e"
      },
      "outputs": [],
      "source": [
        "# --------------- Classifier 1: XGBoost ------------------------------------------\n",
        "xgb = XGBClassifier(n_estimators=15, max_depth=3,\n",
        "                    random_state=42, eval_metric='logloss')\n",
        "\n",
        "# --------------- Classifier 2: Logistic Regression Classifier------------------------------------------\n",
        "lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# --------------- Classifier 3: AdaBoost Classifier ------------------------------------------\n",
        "ada = AdaBoostClassifier(n_estimators=15, random_state=42)\n",
        "\n",
        "# --------------- Classifier 4: SVM------------------------------------------\n",
        "svc = svm.SVC(kernel='rbf', probability=True, random_state=42)\n",
        "\n",
        "# Define a list to store the different models\n",
        "estimator = []\n",
        "estimator.append(('LR', lr))\n",
        "estimator.append(('XGB', xgb))\n",
        "estimator.append(('ada', ada))\n",
        "estimator.append(('SVC', svc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "606c84c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "606c84c3",
        "outputId": "01ceb5a2-42ec-484d-b5dd-46255233df3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('LR', LogisticRegression(random_state=42)),\n",
              "                             ('XGB',\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric='logloss',\n",
              "                                            feature_types=None,\n",
              "                                            feature_weights=None, gamma=None,\n",
              "                                            grow_poli...\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=15, n_jobs=None,\n",
              "                                            num_parallel_tree=None, ...)),\n",
              "                             ('ada',\n",
              "                              AdaBoostClassifier(n_estimators=15,\n",
              "                                                 random_state=42)),\n",
              "                             ('SVC', SVC(probability=True, random_state=42))],\n",
              "                 voting='soft')"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-3 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-3 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-3 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-3 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-3 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-3 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-3 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;LR&#x27;, LogisticRegression(random_state=42)),\n",
              "                             (&#x27;XGB&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=&#x27;logloss&#x27;,\n",
              "                                            feature_types=None,\n",
              "                                            feature_weights=None, gamma=None,\n",
              "                                            grow_poli...\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=15, n_jobs=None,\n",
              "                                            num_parallel_tree=None, ...)),\n",
              "                             (&#x27;ada&#x27;,\n",
              "                              AdaBoostClassifier(n_estimators=15,\n",
              "                                                 random_state=42)),\n",
              "                             (&#x27;SVC&#x27;, SVC(probability=True, random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;LR&#x27;, LogisticRegression(random_state=42)),\n",
              "                             (&#x27;XGB&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=&#x27;logloss&#x27;,\n",
              "                                            feature_types=None,\n",
              "                                            feature_weights=None, gamma=None,\n",
              "                                            grow_poli...\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=15, n_jobs=None,\n",
              "                                            num_parallel_tree=None, ...)),\n",
              "                             (&#x27;ada&#x27;,\n",
              "                              AdaBoostClassifier(n_estimators=15,\n",
              "                                                 random_state=42)),\n",
              "                             (&#x27;SVC&#x27;, SVC(probability=True, random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LR</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>XGB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=15, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>ada</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>AdaBoostClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(n_estimators=15, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>SVC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "### Implement voting classifier with hard voting\n",
        "\n",
        "ml_model = VotingClassifier(estimators=estimator, voting='soft')\n",
        "ml_model.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "0d37141d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d37141d",
        "outputId": "e93a6c16-7d57-4ed2-8417-28cbebf970a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[132 115]\n",
            " [138 205]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.49      0.53      0.51       247\n",
            "           1       0.64      0.60      0.62       343\n",
            "\n",
            "    accuracy                           0.57       590\n",
            "   macro avg       0.56      0.57      0.56       590\n",
            "weighted avg       0.58      0.57      0.57       590\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     205          0.577241         0.056312\n",
            "False Positive    115          0.561796         0.047623\n",
            "True Negative     132          0.445514         0.035898\n",
            "False Negative    138          0.446376         0.041590\n"
          ]
        }
      ],
      "source": [
        "y_true = y_test\n",
        "y_pred = ml_model.predict(X_test)\n",
        "y_proba_default = ml_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(y_true, y_pred)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "probability_summary = confusion_probability_summary(y_true, y_pred, y_proba_default)\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(probability_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMmwRwNtWz0l",
        "outputId": "a0c00e47-7b17-4684-f891-440eb587a419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Threshold 0.7):\n",
            "[[245   2]\n",
            " [335   8]]\n",
            "\n",
            "Classification Report (Threshold 0.7):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.99      0.59       247\n",
            "           1       0.80      0.02      0.05       343\n",
            "\n",
            "    accuracy                           0.43       590\n",
            "   macro avg       0.61      0.51      0.32       590\n",
            "weighted avg       0.64      0.43      0.27       590\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome (Threshold 0.7):\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive       8          0.726667         0.018372\n",
            "False Positive      2          0.734434         0.000478\n",
            "True Negative     245          0.497737         0.068535\n",
            "False Negative    335          0.519764         0.076570\n"
          ]
        }
      ],
      "source": [
        "# Evaluate ML model using a 0.7 probability threshold for class 1\n",
        "y_proba = ml_model.predict_proba(X_test)[:, 1]\n",
        "y_pred_threshold = (y_proba >= 0.7).astype(int)\n",
        "\n",
        "conf_matrix_threshold = confusion_matrix(y_true, y_pred_threshold)\n",
        "print(\"Confusion Matrix (Threshold 0.7):\")\n",
        "print(conf_matrix_threshold)\n",
        "\n",
        "class_report_threshold = classification_report(y_true, y_pred_threshold)\n",
        "print(\"\\nClassification Report (Threshold 0.7):\")\n",
        "print(class_report_threshold)\n",
        "\n",
        "probability_summary_threshold = confusion_probability_summary(y_true, y_pred_threshold, y_proba)\n",
        "print(\"\\nProbability Summary by Confusion Outcome (Threshold 0.7):\")\n",
        "print(probability_summary_threshold)\n"
      ],
      "id": "qMmwRwNtWz0l"
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "dCEg0X2E04iQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCEg0X2E04iQ",
        "outputId": "37ae15a8-7953-41ee-d936-0260fe5de980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at: /content/drive/MyDrive/Course Folder/Forex/XAUUSD/Models/XAUUSD_Short_ml_model.joblib\n"
          ]
        }
      ],
      "source": [
        "### Save ML Model\n",
        "model_path = root_data + 'Models/'+symbol+'_'+direction+'_ml_model.joblib'\n",
        "joblib.dump(ml_model, model_path)\n",
        "print(f\"Model saved successfully at: {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rhCVvXKxM2Uk",
      "metadata": {
        "id": "rhCVvXKxM2Uk"
      },
      "source": [
        "## Meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "PhMU7vwLPag_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhMU7vwLPag_",
        "outputId": "9ae3897e-e583-4ca1-f5f5-1d915ac8fb33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from: /content/drive/MyDrive/Course Folder/Forex/XAUUSD/Models/XAUUSD_Short_ml_model.joblib\n"
          ]
        }
      ],
      "source": [
        "### Import ML Model\n",
        "model_path = root_data+'Models/'+symbol+'_'+direction+'_ml_model.joblib'\n",
        "ml_model = joblib.load(model_path)\n",
        "print(f\"Model loaded successfully from: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "qszEBUJ-4GCn",
      "metadata": {
        "id": "qszEBUJ-4GCn"
      },
      "outputs": [],
      "source": [
        "#train.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "yRXiqFivOSNq",
      "metadata": {
        "id": "yRXiqFivOSNq"
      },
      "outputs": [],
      "source": [
        "### Import Data\n",
        "start_feature = train.columns.get_loc('10min_RSI_3_diff')\n",
        "train_features = [col for col in train.columns[start_feature:] if col != 'label']\n",
        "\n",
        "# Select the feature columns from the 'train' DataFrame\n",
        "X_train_features = train[train_features]\n",
        "\n",
        "train['label_ml'] = ml_model.predict(X_train_features)\n",
        "\n",
        "prediction_probabilities = ml_model.predict_proba(X_train_features)\n",
        "train['prob_0'] = prediction_probabilities[:, 0]\n",
        "train['prob_1'] = prediction_probabilities[:, 1]\n",
        "\n",
        "# Additional outputs of the initial model to feed into the meta model.\n",
        "\n",
        "#meta_manual_features = ['label_ml', 'prob_1', 'prob_0']\n",
        "meta_manual_features = ['prob_1']\n",
        "meta_features = train_features + meta_manual_features\n",
        "X_meta_features = train[meta_features]\n",
        "\n",
        "#train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "a7PKPf5CxaRx",
      "metadata": {
        "id": "a7PKPf5CxaRx"
      },
      "outputs": [],
      "source": [
        "train.to_csv(root_data + 'Results/'+symbol+'Meta_Prob_M5+M10_train_l.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "XVlPvtGoxaRy",
      "metadata": {
        "id": "XVlPvtGoxaRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7792c708-35d2-42fb-89e2-f1afbbd6f98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_train: (1375, 235)\n",
            "Shape of X_test: (590, 235)\n",
            "Shape of y_train: (1375,)\n",
            "Shape of y_test: (590,)\n"
          ]
        }
      ],
      "source": [
        "# Adjust the manual meta features in 'meta_manual_features' if different inputs are required.\n",
        "meta = meta_features.copy()\n",
        "X_meta_features = train[meta]\n",
        "\n",
        "X = train[meta]\n",
        "y = train['label']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "3rPgnEbGxaRy",
      "metadata": {
        "id": "3rPgnEbGxaRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5489ab48-1bc2-431a-ddd9-fad9316b6a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "1    719\n",
            "0    656\n",
            "Name: count, dtype: int64\n",
            "label\n",
            "1    343\n",
            "0    247\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(y_train.value_counts())\n",
        "print(y_test.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "VeHU0htFxaRy",
      "metadata": {
        "id": "VeHU0htFxaRy"
      },
      "outputs": [],
      "source": [
        "### Rebalance Data frame due to the low number of class 1\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "2XmqHiZBxaRy",
      "metadata": {
        "id": "2XmqHiZBxaRy"
      },
      "outputs": [],
      "source": [
        "# --------------- Classifier 1: XGBoost ------------------------------------------\n",
        "xgb = XGBClassifier(n_estimators=15, max_depth=3,\n",
        "                    random_state=42, eval_metric='logloss')\n",
        "\n",
        "# --------------- Classifier 2: Logistic Regression Classifier------------------------------------------\n",
        "lr = LogisticRegression(random_state=42)\n",
        "\n",
        "# --------------- Classifier 3: AdaBoost Classifier ------------------------------------------\n",
        "ada = AdaBoostClassifier(n_estimators=15, random_state=42)\n",
        "\n",
        "# --------------- Classifier 4: SVM------------------------------------------\n",
        "svc = svm.SVC(kernel='rbf', probability=True, random_state=42)\n",
        "\n",
        "# Define a list to store the different models\n",
        "estimator = []\n",
        "estimator.append(('LR', lr))\n",
        "estimator.append(('XGB', xgb))\n",
        "estimator.append(('ada', ada))\n",
        "estimator.append(('SVC', svc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "2JHZizlExaRy",
      "metadata": {
        "id": "2JHZizlExaRy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c86d0992-801d-447b-81a8-87d3a5146879"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VotingClassifier(estimators=[('LR', LogisticRegression(random_state=42)),\n",
              "                             ('XGB',\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric='logloss',\n",
              "                                            feature_types=None,\n",
              "                                            feature_weights=None, gamma=None,\n",
              "                                            grow_poli...\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=15, n_jobs=None,\n",
              "                                            num_parallel_tree=None, ...)),\n",
              "                             ('ada',\n",
              "                              AdaBoostClassifier(n_estimators=15,\n",
              "                                                 random_state=42)),\n",
              "                             ('SVC', SVC(probability=True, random_state=42))],\n",
              "                 voting='soft')"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-4 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-4 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-4 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-4 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-4 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-4 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-4 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;LR&#x27;, LogisticRegression(random_state=42)),\n",
              "                             (&#x27;XGB&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=&#x27;logloss&#x27;,\n",
              "                                            feature_types=None,\n",
              "                                            feature_weights=None, gamma=None,\n",
              "                                            grow_poli...\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=15, n_jobs=None,\n",
              "                                            num_parallel_tree=None, ...)),\n",
              "                             (&#x27;ada&#x27;,\n",
              "                              AdaBoostClassifier(n_estimators=15,\n",
              "                                                 random_state=42)),\n",
              "                             (&#x27;SVC&#x27;, SVC(probability=True, random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>VotingClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.VotingClassifier.html\">?<span>Documentation for VotingClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>VotingClassifier(estimators=[(&#x27;LR&#x27;, LogisticRegression(random_state=42)),\n",
              "                             (&#x27;XGB&#x27;,\n",
              "                              XGBClassifier(base_score=None, booster=None,\n",
              "                                            callbacks=None,\n",
              "                                            colsample_bylevel=None,\n",
              "                                            colsample_bynode=None,\n",
              "                                            colsample_bytree=None, device=None,\n",
              "                                            early_stopping_rounds=None,\n",
              "                                            enable_categorical=False,\n",
              "                                            eval_metric=&#x27;logloss&#x27;,\n",
              "                                            feature_types=None,\n",
              "                                            feature_weights=None, gamma=None,\n",
              "                                            grow_poli...\n",
              "                                            max_cat_threshold=None,\n",
              "                                            max_cat_to_onehot=None,\n",
              "                                            max_delta_step=None, max_depth=3,\n",
              "                                            max_leaves=None,\n",
              "                                            min_child_weight=None, missing=nan,\n",
              "                                            monotone_constraints=None,\n",
              "                                            multi_strategy=None,\n",
              "                                            n_estimators=15, n_jobs=None,\n",
              "                                            num_parallel_tree=None, ...)),\n",
              "                             (&#x27;ada&#x27;,\n",
              "                              AdaBoostClassifier(n_estimators=15,\n",
              "                                                 random_state=42)),\n",
              "                             (&#x27;SVC&#x27;, SVC(probability=True, random_state=42))],\n",
              "                 voting=&#x27;soft&#x27;)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>LR</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>XGB</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=&#x27;logloss&#x27;,\n",
              "              feature_types=None, feature_weights=None, gamma=None,\n",
              "              grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=15, n_jobs=None,\n",
              "              num_parallel_tree=None, ...)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>ada</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>AdaBoostClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.AdaBoostClassifier.html\">?<span>Documentation for AdaBoostClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostClassifier(n_estimators=15, random_state=42)</pre></div> </div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><label>SVC</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>SVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(probability=True, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "### Implement voting classifier with hard voting\n",
        "\n",
        "meta_ml_model = VotingClassifier(estimators=estimator, voting='soft')\n",
        "meta_ml_model.fit(X_train_resampled, y_train_resampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "HU43Cg6jVq6j",
      "metadata": {
        "id": "HU43Cg6jVq6j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "809ac3ec-368c-4b7b-b4fe-f9e7ca180670"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[138 109]\n",
            " [138 205]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.56      0.53       247\n",
            "           1       0.65      0.60      0.62       343\n",
            "\n",
            "    accuracy                           0.58       590\n",
            "   macro avg       0.58      0.58      0.58       590\n",
            "weighted avg       0.59      0.58      0.58       590\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     205          0.669182         0.092511\n",
            "False Positive    109          0.652047         0.080804\n",
            "True Negative     138          0.360181         0.084130\n",
            "False Negative    138          0.359298         0.088929\n"
          ]
        }
      ],
      "source": [
        "y_true = y_test\n",
        "y_pred = meta_ml_model.predict(X_test)\n",
        "meta_y_proba_default = meta_ml_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "class_report = classification_report(y_true, y_pred)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "probability_summary = confusion_probability_summary(y_true, y_pred, meta_y_proba_default)\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(probability_summary)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "pZXiSkdiWz0u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df511b0-e3b3-4a4d-f764-86724293e573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Threshold 0.7):\n",
            "[[216  31]\n",
            " [263  80]]\n",
            "\n",
            "Classification Report (Threshold 0.7):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.87      0.60       247\n",
            "           1       0.72      0.23      0.35       343\n",
            "\n",
            "    accuracy                           0.50       590\n",
            "   macro avg       0.59      0.55      0.47       590\n",
            "weighted avg       0.61      0.50      0.45       590\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome (Threshold 0.7):\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive      80          0.767738         0.037558\n",
            "False Positive     31          0.752038         0.036170\n",
            "True Negative     216          0.451226         0.142441\n",
            "False Negative    263          0.476602         0.144004\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Meta ML model using a 0.7 probability threshold for class 1\n",
        "meta_y_proba = meta_ml_model.predict_proba(X_test)[:, 1]\n",
        "meta_y_pred_threshold = (meta_y_proba >= 0.7).astype(int)\n",
        "\n",
        "meta_conf_matrix_threshold = confusion_matrix(y_true, meta_y_pred_threshold)\n",
        "print(\"Confusion Matrix (Threshold 0.7):\")\n",
        "print(meta_conf_matrix_threshold)\n",
        "\n",
        "meta_class_report_threshold = classification_report(y_true, meta_y_pred_threshold)\n",
        "print(\"\\nClassification Report (Threshold 0.7):\")\n",
        "print(meta_class_report_threshold)\n",
        "\n",
        "meta_probability_summary_threshold = confusion_probability_summary(y_true, meta_y_pred_threshold, meta_y_proba)\n",
        "print(\"\\nProbability Summary by Confusion Outcome (Threshold 0.7):\")\n",
        "print(meta_probability_summary_threshold)\n"
      ],
      "id": "pZXiSkdiWz0u"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "tAR97BLJu44I",
      "metadata": {
        "id": "tAR97BLJu44I"
      },
      "outputs": [],
      "source": [
        "train['meta_results'] = meta_ml_model.predict(X_meta_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "ysM6YjQAj8QR",
      "metadata": {
        "id": "ysM6YjQAj8QR"
      },
      "outputs": [],
      "source": [
        "train.to_csv(root_data + 'Results/'+symbol+'train_l_Signals & Meta_Signals.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "8Y71USlnxaRz",
      "metadata": {
        "id": "8Y71USlnxaRz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4e6555-df23-4aab-9ade-bc0a5e4371cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully at: /content/drive/MyDrive/Course Folder/Forex/XAUUSD/Models/XAUUSD_Short_Meta_ml_model.joblib\n"
          ]
        }
      ],
      "source": [
        "### Save ML Model\n",
        "model_path = root_data + 'Models/'+symbol+'_'+direction+'_Meta_ml_model.joblib'\n",
        "joblib.dump(meta_ml_model, model_path)\n",
        "print(f\"Model saved successfully at: {model_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dX1ehVSJJRC9",
      "metadata": {
        "id": "dX1ehVSJJRC9"
      },
      "source": [
        "## PnL Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "kUfGrpS7kxyW",
      "metadata": {
        "id": "kUfGrpS7kxyW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "60d2dc45-5322-44a8-f0b8-545130d894a0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'st_PnL'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'st_PnL'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2198732896.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ml_results'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label_ml'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'st_PnL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnl_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ml_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'st_PnL'"
          ]
        }
      ],
      "source": [
        "train['ml_results'] = np.where(train['label_ml']==1, train['st_PnL'],0)\n",
        "results(train, pnl_column='ml_results')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "USsAkHmUYkHT",
      "metadata": {
        "id": "USsAkHmUYkHT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "446a612a-c647-457f-c39f-40cb51a87675"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'st_PnL'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'st_PnL'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3829643427.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta_ml_results'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta_results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'st_PnL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpnl_column\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'meta_ml_results'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'st_PnL'"
          ]
        }
      ],
      "source": [
        "train['meta_ml_results'] = np.where(train['meta_results']==1, train['st_PnL'],0)\n",
        "results(train, pnl_column='meta_ml_results')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60f86dad",
      "metadata": {
        "id": "60f86dad"
      },
      "source": [
        "\n",
        "# Test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "q7HA2vsxuup9",
      "metadata": {
        "id": "q7HA2vsxuup9"
      },
      "source": [
        "## Results_ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "5Y218WrFnt-E",
      "metadata": {
        "id": "5Y218WrFnt-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095873f7-65b4-4b91-cbfc-7896e084b0c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from: /content/drive/MyDrive/Course Folder/Forex/XAUUSD/Models/XAUUSD_Short_ml_model.joblib\n"
          ]
        }
      ],
      "source": [
        "### Import ML Model\n",
        "\n",
        "model_path = root_data+'Models/'+symbol+'_'+direction+'_ml_model.joblib'\n",
        "ml_model = joblib.load(model_path)\n",
        "print(f\"Model loaded successfully from: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "YiE7uKuaDqmf",
      "metadata": {
        "id": "YiE7uKuaDqmf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ba2bcb9-2231-47e3-8807-22a6bbeb3089"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded successfully from: /content/drive/MyDrive/Course Folder/Forex/XAUUSD/Models/XAUUSD_Short_Meta_ml_model.joblib\n"
          ]
        }
      ],
      "source": [
        "### Import Meta Model\n",
        "\n",
        "model_path = root_data+'Models/'+symbol+'_'+direction+'_Meta_ml_model.joblib'\n",
        "meta_ml_model = joblib.load(model_path)\n",
        "print(f\"Model loaded successfully from: {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "TGSpa4ZWrC3K",
      "metadata": {
        "id": "TGSpa4ZWrC3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6208f1f1-74c4-42e5-e1a1-ec55d51c9cb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[188 197]\n",
            " [183 275]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.49      0.50       385\n",
            "           1       0.58      0.60      0.59       458\n",
            "\n",
            "    accuracy                           0.55       843\n",
            "   macro avg       0.54      0.54      0.54       843\n",
            "weighted avg       0.55      0.55      0.55       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     275          0.574630         0.054289\n",
            "False Positive    197          0.558941         0.041950\n",
            "True Negative     188          0.444203         0.040618\n",
            "False Negative    183          0.443418         0.038438\n"
          ]
        }
      ],
      "source": [
        "# Select the feature columns from the 'test' DataFrame\n",
        "X_test_features = test[train_features]\n",
        "\n",
        "test['label_ml'] = ml_model.predict(X_test_features)\n",
        "\n",
        "prediction_probabilities_test = ml_model.predict_proba(X_test_features)\n",
        "test['prob_0'] = prediction_probabilities_test[:, 0]\n",
        "test['prob_1'] = prediction_probabilities_test[:, 1]\n",
        "\n",
        "# Calculate and display Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test['label'], test['label_ml'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and display Classification Report\n",
        "class_report = classification_report(test['label'], test['label_ml'])\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "probability_summary_test = confusion_probability_summary(test['label'], test['label_ml'], test['prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(probability_summary_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "L5v-IETUsv9j",
      "metadata": {
        "id": "L5v-IETUsv9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80f178e6-9d8d-4b53-9c9e-de47936a3f19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[188 197]\n",
            " [183 275]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.49      0.50       385\n",
            "           1       0.58      0.60      0.59       458\n",
            "\n",
            "    accuracy                           0.55       843\n",
            "   macro avg       0.54      0.54      0.54       843\n",
            "weighted avg       0.55      0.55      0.55       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     275          0.574630         0.054289\n",
            "False Positive    197          0.558941         0.041950\n",
            "True Negative     188          0.444203         0.040618\n",
            "False Negative    183          0.443418         0.038438\n"
          ]
        }
      ],
      "source": [
        "# Calculate and display Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test['label'], test['label_ml'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and display Classification Report\n",
        "class_report = classification_report(test['label'], test['label_ml'])\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "probability_summary_test = confusion_probability_summary(test['label'], test['label_ml'], test['prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(probability_summary_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "fU7IXWiGWz0x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401601b3-121b-40ac-f2be-c52856854159"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Threshold 0.7):\n",
            "[[385   0]\n",
            " [452   6]]\n",
            "\n",
            "Classification Report (Threshold 0.7):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      1.00      0.63       385\n",
            "           1       1.00      0.01      0.03       458\n",
            "\n",
            "    accuracy                           0.46       843\n",
            "   macro avg       0.73      0.51      0.33       843\n",
            "weighted avg       0.75      0.46      0.30       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome (Threshold 0.7):\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive       6          0.732589         0.025616\n",
            "False Positive      0               NaN              NaN\n",
            "True Negative     385          0.502913         0.070679\n",
            "False Negative    452          0.519410         0.077282\n"
          ]
        }
      ],
      "source": [
        "# Evaluate ML model on the test set using a 0.7 probability threshold for class 1\n",
        "test['label_ml_prob_70'] = np.where(test['prob_1'] >= 0.7, 1, 0)\n",
        "\n",
        "conf_matrix_prob_70 = confusion_matrix(test['label'], test['label_ml_prob_70'])\n",
        "print(\"Confusion Matrix (Threshold 0.7):\")\n",
        "print(conf_matrix_prob_70)\n",
        "\n",
        "class_report_prob_70 = classification_report(test['label'], test['label_ml_prob_70'])\n",
        "print(\"\\nClassification Report (Threshold 0.7):\")\n",
        "print(class_report_prob_70)\n",
        "\n",
        "probability_summary_prob_70 = confusion_probability_summary(test['label'], test['label_ml_prob_70'], test['prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome (Threshold 0.7):\")\n",
        "print(probability_summary_prob_70)\n"
      ],
      "id": "fU7IXWiGWz0x"
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "O0tSbMwArC8a",
      "metadata": {
        "id": "O0tSbMwArC8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ca6b1c-d8b0-4c34-a48d-2b36a8719191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[199 186]\n",
            " [189 269]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.52      0.51       385\n",
            "           1       0.59      0.59      0.59       458\n",
            "\n",
            "    accuracy                           0.56       843\n",
            "   macro avg       0.55      0.55      0.55       843\n",
            "weighted avg       0.56      0.56      0.56       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     269          0.670808         0.092929\n",
            "False Positive    186          0.644196         0.082007\n",
            "True Negative     199          0.358360         0.090912\n",
            "False Negative    189          0.352198         0.086966\n"
          ]
        }
      ],
      "source": [
        "# Select the feature columns for the meta model from the 'test' DataFrame\n",
        "X_meta_features_test = test[meta]\n",
        "\n",
        "# Predict using the meta model on the test set\n",
        "test['meta_label'] = meta_ml_model.predict(X_meta_features_test)\n",
        "meta_prediction_probabilities_test = meta_ml_model.predict_proba(X_meta_features_test)\n",
        "test['meta_prob_0'] = meta_prediction_probabilities_test[:, 0]\n",
        "test['meta_prob_1'] = meta_prediction_probabilities_test[:, 1]\n",
        "\n",
        "\n",
        "# Calculate and display Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test['label'], test['meta_label'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and display Classification Report\n",
        "class_report = classification_report(test['label'], test['meta_label'])\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "meta_probability_summary_test = confusion_probability_summary(test['label'], test['meta_label'], test['meta_prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(meta_probability_summary_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "SgIOg4eErC_H",
      "metadata": {
        "id": "SgIOg4eErC_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f431c968-8712-4b3b-d4bb-c76164aee181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[199 186]\n",
            " [189 269]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.52      0.51       385\n",
            "           1       0.59      0.59      0.59       458\n",
            "\n",
            "    accuracy                           0.56       843\n",
            "   macro avg       0.55      0.55      0.55       843\n",
            "weighted avg       0.56      0.56      0.56       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     269          0.670808         0.092929\n",
            "False Positive    186          0.644196         0.082007\n",
            "True Negative     199          0.358360         0.090912\n",
            "False Negative    189          0.352198         0.086966\n"
          ]
        }
      ],
      "source": [
        "# Calculate and display Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test['label'], test['meta_label'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and display Classification Report\n",
        "class_report = classification_report(test['label'], test['meta_label'])\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "meta_probability_summary_test = confusion_probability_summary(test['label'], test['meta_label'], test['meta_prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(meta_probability_summary_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "WcQPv6u2Wz0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a920c06-9be9-42ae-b4fe-438a27f1b5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix (Threshold 0.7):\n",
            "[[331  54]\n",
            " [352 106]]\n",
            "\n",
            "Classification Report (Threshold 0.7):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.86      0.62       385\n",
            "           1       0.66      0.23      0.34       458\n",
            "\n",
            "    accuracy                           0.52       843\n",
            "   macro avg       0.57      0.55      0.48       843\n",
            "weighted avg       0.58      0.52      0.47       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome (Threshold 0.7):\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     106          0.768361         0.037207\n",
            "False Positive     54          0.748963         0.033761\n",
            "True Negative     331          0.455257         0.142104\n",
            "False Negative    352          0.470359         0.147321\n"
          ]
        }
      ],
      "source": [
        "# Evaluate Meta ML model on the test set using a 0.7 probability threshold for class 1\n",
        "test['meta_label_prob_70'] = np.where(test['meta_prob_1'] >= 0.7, 1, 0)\n",
        "\n",
        "meta_conf_matrix_prob_70 = confusion_matrix(test['label'], test['meta_label_prob_70'])\n",
        "print(\"Confusion Matrix (Threshold 0.7):\")\n",
        "print(meta_conf_matrix_prob_70)\n",
        "\n",
        "meta_class_report_prob_70 = classification_report(test['label'], test['meta_label_prob_70'])\n",
        "print(\"\\nClassification Report (Threshold 0.7):\")\n",
        "print(meta_class_report_prob_70)\n",
        "\n",
        "meta_probability_summary_prob_70 = confusion_probability_summary(test['label'], test['meta_label_prob_70'], test['meta_prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome (Threshold 0.7):\")\n",
        "print(meta_probability_summary_prob_70)\n"
      ],
      "id": "WcQPv6u2Wz0y"
    },
    {
      "cell_type": "markdown",
      "id": "_5BjO-5fvFjb",
      "metadata": {
        "id": "_5BjO-5fvFjb"
      },
      "source": [
        "## Results_PnL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "gj0_nEvuvvjB",
      "metadata": {
        "id": "gj0_nEvuvvjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95ec5aa-3361-41f7-ed63-d887825f9d4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[188 197]\n",
            " [183 275]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.49      0.50       385\n",
            "           1       0.58      0.60      0.59       458\n",
            "\n",
            "    accuracy                           0.55       843\n",
            "   macro avg       0.54      0.54      0.54       843\n",
            "weighted avg       0.55      0.55      0.55       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     275          0.574630         0.054289\n",
            "False Positive    197          0.558941         0.041950\n",
            "True Negative     188          0.444203         0.040618\n",
            "False Negative    183          0.443418         0.038438\n"
          ]
        }
      ],
      "source": [
        "# Calculate and display Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test['label'], test['label_ml'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and display Classification Report\n",
        "class_report = classification_report(test['label'], test['label_ml'])\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "probability_summary_test = confusion_probability_summary(test['label'], test['label_ml'], test['prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(probability_summary_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "id": "-iktKy5uvvjC",
      "metadata": {
        "id": "-iktKy5uvvjC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315341b6-858e-4410-c081-6237fd3abd85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[199 186]\n",
            " [189 269]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.51      0.52      0.51       385\n",
            "           1       0.59      0.59      0.59       458\n",
            "\n",
            "    accuracy                           0.56       843\n",
            "   macro avg       0.55      0.55      0.55       843\n",
            "weighted avg       0.56      0.56      0.56       843\n",
            "\n",
            "\n",
            "Probability Summary by Confusion Outcome:\n",
            "                Count  Mean Probability  Std Probability\n",
            "Outcome                                                 \n",
            "True Positive     269          0.670808         0.092929\n",
            "False Positive    186          0.644196         0.082007\n",
            "True Negative     199          0.358360         0.090912\n",
            "False Negative    189          0.352198         0.086966\n"
          ]
        }
      ],
      "source": [
        "# Calculate and display Confusion Matrix\n",
        "conf_matrix = confusion_matrix(test['label'], test['meta_label'])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Calculate and display Classification Report\n",
        "class_report = classification_report(test['label'], test['meta_label'])\n",
        "print(\"\\nClassification Report:\")\n",
        "print(class_report)\n",
        "\n",
        "meta_probability_summary_test = confusion_probability_summary(test['label'], test['meta_label'], test['meta_prob_1'])\n",
        "print(\"\\nProbability Summary by Confusion Outcome:\")\n",
        "print(meta_probability_summary_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0410fd8b",
      "metadata": {
        "id": "0410fd8b"
      },
      "source": [
        "# Pendientes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CNhE1wXGVTYf",
      "metadata": {
        "id": "CNhE1wXGVTYf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "m8CIB8vltFfH",
        "eaf03429",
        "zhTndYVi1TEV",
        "6x4lfhG3E2eq",
        "rhCVvXKxM2Uk",
        "dX1ehVSJJRC9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}