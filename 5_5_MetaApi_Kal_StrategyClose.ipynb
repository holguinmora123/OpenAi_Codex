{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "eaf03429",
      "metadata": {
        "id": "eaf03429"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bda1a01c",
      "metadata": {
        "id": "bda1a01c"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import asyncio\n",
        "import datetime as dt\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "import sys\n",
        "import traceback\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Any, Callable, Dict, List, Mapping, Optional, Sequence, Tuple\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "import talib as ta\n",
        "import warnings\n",
        "\n",
        "try:\n",
        "    from metaapi_cloud_sdk import MetaApi\n",
        "    from metaapi_cloud_sdk.clients.timeout_exception import TimeoutException\n",
        "except Exception:  # pragma: no cover - fallback when SDK is unavailable\n",
        "    MetaApi = None  # type: ignore[assignment]\n",
        "\n",
        "    class TimeoutException(Exception):\n",
        "        \"\"\"Fallback TimeoutException when metaapi_cloud_sdk is unavailable.\"\"\"\n",
        "        pass\n",
        "\n",
        "nest_asyncio.apply()\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"seaborn-v0_8-darkgrid\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "m8CIB8vltFfH",
      "metadata": {
        "id": "m8CIB8vltFfH"
      },
      "source": [
        "# Set_Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EB5RqjoAtFwl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EB5RqjoAtFwl",
        "outputId": "5f1ccc18-981d-49b5-f6e9-5dda19605491"
      },
      "outputs": [],
      "source": [
        "@dataclass(frozen=True)\n",
        "class StrategyConfig:\n",
        "    symbol: str\n",
        "    timeframe: str\n",
        "    candles: int\n",
        "    lot: float\n",
        "    comment: str\n",
        "    lengths: Tuple[int, int, int, int]\n",
        "    smooths: Tuple[int, int, int, int]\n",
        "    initial_sl: float\n",
        "    first_step_atr: float\n",
        "    gap_first_step_atr: float\n",
        "    magic: int\n",
        "    region: str\n",
        "    data_path: str\n",
        "    meta_api_token: str\n",
        "    account_id: str\n",
        "\n",
        "\n",
        "def _int_env(name: str, default: int) -> int:\n",
        "    return int(os.environ.get(name, str(default)))\n",
        "\n",
        "\n",
        "def _float_env(name: str, default: float) -> float:\n",
        "    return float(os.environ.get(name, str(default)))\n",
        "\n",
        "\n",
        "def _str_env(name: str, default: str) -> str:\n",
        "    return os.environ.get(name, default)\n",
        "\n",
        "\n",
        "_DEFAULT_SYMBOL = \"XAUUSD\"\n",
        "_SYMBOL = _str_env(\"STRATEGY_SYMBOL\", _DEFAULT_SYMBOL)\n",
        "_DATA_DIR = Path(_str_env(\"STRATEGY_DATA_DIR\", \".\"))\n",
        "_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "_file_name = _str_env(\"STRATEGY_FILE_PATH\", f\"{_SYMBOL.lower()}_data.csv\")\n",
        "_file_path = Path(_file_name)\n",
        "if not _file_path.is_absolute():\n",
        "    _file_path = _DATA_DIR / _file_path\n",
        "\n",
        "_LENGTHS = (\n",
        "    _int_env(\"STRATEGY_LENGTH_1\", 600),\n",
        "    _int_env(\"STRATEGY_LENGTH_2\", 520),\n",
        "    _int_env(\"STRATEGY_LENGTH_3\", 710),\n",
        "    _int_env(\"STRATEGY_LENGTH_4\", 1130),\n",
        ")\n",
        "_SMOOTHS = (\n",
        "    _int_env(\"STRATEGY_SMOOTH_1\", 3),\n",
        "    _int_env(\"STRATEGY_SMOOTH_2\", 3),\n",
        "    _int_env(\"STRATEGY_SMOOTH_3\", 3),\n",
        "    _int_env(\"STRATEGY_SMOOTH_4\", 7),\n",
        ")\n",
        "\n",
        "CONFIG = StrategyConfig(\n",
        "    symbol=_SYMBOL,\n",
        "    timeframe=_str_env(\"STRATEGY_TIMEFRAME\", \"1m\"),\n",
        "    candles=_int_env(\"STRATEGY_CANDLE_NUMBER\", 900),\n",
        "    lot=_float_env(\"STRATEGY_LOT\", 0.5),\n",
        "    comment=_str_env(\"STRATEGY_COMMENT\", \"Kalman\"),\n",
        "    lengths=_LENGTHS,\n",
        "    smooths=_SMOOTHS,\n",
        "    initial_sl=_float_env(\"STRATEGY_INITIAL_SL\", -2.0),\n",
        "    first_step_atr=_float_env(\"STRATEGY_FIRST_STEP_ATR\", 0.5),\n",
        "    gap_first_step_atr=_float_env(\"STRATEGY_GAP_FIRST_STEP_ATR\", 2.0),\n",
        "    magic=_int_env(\"STRATEGY_MAGIC\", 900001),\n",
        "    region=_str_env(\"META_API_REGION\", \"london\"),\n",
        "    data_path=str(_file_path),\n",
        "    meta_api_token=_str_env(\"META_API_TOKEN\", \"\"),\n",
        "    account_id=_str_env(\"META_API_ACCOUNT_ID\", \"\"),\n",
        ")\n",
        "\n",
        "SYMBOL = CONFIG.symbol\n",
        "FILE_PATH = CONFIG.data_path\n",
        "CANDEL_NUMBER = CONFIG.candles\n",
        "LOT = CONFIG.lot\n",
        "LOT_ = CONFIG.lot\n",
        "COMMENT = CONFIG.comment\n",
        "COMMENT_ = CONFIG.comment\n",
        "time_frame_data = CONFIG.timeframe\n",
        "length_1, length_2, length_3, length_4 = CONFIG.lengths\n",
        "smooth_1, smooth_2, smooth_3, smooth_4 = CONFIG.smooths\n",
        "INITIAL_SL = CONFIG.initial_sl\n",
        "FIRST_STEP_ATR = CONFIG.first_step_atr\n",
        "GAP_FIRST_STEP_ATR = CONFIG.gap_first_step_atr\n",
        "MAGIC = CONFIG.magic\n",
        "META_API_TOKEN = CONFIG.meta_api_token\n",
        "ACCOUNT_ID = CONFIG.account_id\n",
        "REGION = CONFIG.region\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dTlwjirFwRfj",
      "metadata": {
        "id": "dTlwjirFwRfj"
      },
      "outputs": [],
      "source": [
        "# cache simple en m\u00f3dulo\n",
        "__CONNECTION_CHECKED = False\n",
        "__ACCOUNT_CONN: Optional[Tuple[object, object]] = None  # (account, rpc_conn)\n",
        "\n",
        "async def _connect_and_validate_async(token: str, account_id: str) -> Tuple[object, object]:\n",
        "    \"\"\"\n",
        "    Conecta v\u00eda RPC y espera sincronizaci\u00f3n. Lanza excepci\u00f3n si no se logra.\n",
        "    Devuelve (account, rpc_conn).\n",
        "    \"\"\"\n",
        "    api = MetaApi(token)\n",
        "    account = await api.metatrader_account_api.get_account(account_id)\n",
        "\n",
        "    # refrescamos para leer estado/connectionStatus\n",
        "    try:\n",
        "        await account.reload()\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # Conexi\u00f3n RPC + sincronizaci\u00f3n del terminal\n",
        "    rpc_conn = account.get_rpc_connection()\n",
        "    await rpc_conn.connect()\n",
        "    await rpc_conn.wait_synchronized()  # espera a que el terminal est\u00e9 listo\n",
        "\n",
        "    # Sonda r\u00e1pida para confirmar conectividad real con el terminal\n",
        "    try:\n",
        "        _ = await rpc_conn.get_account_information()\n",
        "    except Exception:\n",
        "        # si falla la sonda, igual devolvemos la conexi\u00f3n (ya sincronizada)\n",
        "        pass\n",
        "\n",
        "    return account, rpc_conn\n",
        "\n",
        "def _run(coro):\n",
        "    \"\"\"Ejecuta corutinas tanto en script como en notebook.\"\"\"\n",
        "    try:\n",
        "        return asyncio.run(coro)\n",
        "    except RuntimeError:\n",
        "        # evento ya corriendo (Jupyter): usamos el loop actual\n",
        "        loop = asyncio.get_event_loop()\n",
        "        return loop.run_until_complete(coro)\n",
        "\n",
        "def check_connection_once(token: str, account_id: str) -> bool:\n",
        "    \"\"\"\n",
        "    Valida la conexi\u00f3n y sincronizaci\u00f3n SOLO la primera vez que se llama.\n",
        "    En llamadas posteriores no vuelve a conectar.\n",
        "    \"\"\"\n",
        "    global __CONNECTION_CHECKED, __ACCOUNT_CONN\n",
        "    if __CONNECTION_CHECKED:\n",
        "        print(\"\u2139\ufe0f Conexi\u00f3n ya validada en esta sesi\u00f3n; no se repite.\")\n",
        "        return True\n",
        "\n",
        "    try:\n",
        "        account, rpc_conn = _run(_connect_and_validate_async(token, account_id))\n",
        "        __ACCOUNT_CONN = (account, rpc_conn)\n",
        "        __CONNECTION_CHECKED = True\n",
        "        print(f\"\u2705 Conectado y sincronizado con MetaApi. account_id={account_id}\")\n",
        "        return True\n",
        "    except TimeoutException as e:\n",
        "        print(f\"\u274c Timeout esperando sincronizaci\u00f3n. \u00bfLa cuenta est\u00e1 CONNECTED al broker? Detalle: {e}\")\n",
        "        return False\n",
        "    except Exception as e:\n",
        "        print(f\"\u274c No fue posible validar la conexi\u00f3n. Error: {e}\")\n",
        "        return False\n",
        "\n",
        "def _safe_json_dump(value):\n",
        "    try:\n",
        "        return json.dumps(value, indent=2, default=str)\n",
        "    except Exception:\n",
        "        return str(value)\n",
        "\n",
        "def print_order_error_details(ctx: dict, err: Exception):\n",
        "    \"\"\"Pretty-print as much structured info as we can from MetaApi errors.\"\"\"\n",
        "    print(\"\\n\" + \"\u2718\" * 70)\n",
        "    print(\"\u274c Order failed\")\n",
        "    print(\"\u2022 Exception type:\", type(err).__name__)\n",
        "    print(\"\u2022 Message       :\", str(err))\n",
        "\n",
        "    # Known useful attributes often present on MetaApi exceptions\n",
        "    for attr in (\"details\", \"error\", \"status\", \"code\", \"description\", \"response\", \"body\"):\n",
        "        if hasattr(err, attr):\n",
        "            val = getattr(err, attr)\n",
        "            if val:\n",
        "                print(f\"\u2022 {attr:12}: {_safe_json_dump(val)}\")\n",
        "\n",
        "    # Try to parse a JSON object embedded in the message (common in SDKs)\n",
        "    msg = str(err)\n",
        "    m = re.search(r\"\\{.*\\}\", msg)\n",
        "    if m:\n",
        "        try:\n",
        "            payload = json.loads(m.group(0))\n",
        "            print(\"\u2022 parsed_json  :\", _safe_json_dump(payload))\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Stack (useful while debugging)\n",
        "    print(\"\u2022 traceback    :\")\n",
        "    traceback.print_exc()\n",
        "\n",
        "    # Context of the attempt\n",
        "    print(\"\u2022 context      :\", _safe_json_dump(ctx))\n",
        "    print(\"\u2718\" * 70 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "RjShygBIwWRp",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjShygBIwWRp",
        "outputId": "1c85d83e-5876-48d7-e8e3-f923e2829e69"
      },
      "outputs": [],
      "source": [
        "if META_API_TOKEN and ACCOUNT_ID:\n",
        "    check_connection_once(META_API_TOKEN, ACCOUNT_ID)\n",
        "else:\n",
        "    logging.info(\"MetaApi credentials not provided; connection check skipped.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HfxZvvtJeFh1",
      "metadata": {
        "id": "HfxZvvtJeFh1"
      },
      "source": [
        "# Real_Life"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cvhz3M-fTIw",
      "metadata": {
        "id": "5cvhz3M-fTIw"
      },
      "outputs": [],
      "source": [
        "async def main():\n",
        "    \"\"\"\n",
        "    Bucle principal:\n",
        "      \u2022 Crea/migra el CSV inicial (ATR interno, se\u00f1ales Kalman).\n",
        "      \u2022 Cada 5 minutos procesa la \u00faltima vela cerrada y, si corresponde,\n",
        "        abre una operaci\u00f3n con stop-loss.\n",
        "    \"\"\"\n",
        "\n",
        "    if not META_API_TOKEN or not ACCOUNT_ID:\n",
        "        raise RuntimeError(\"MetaApi credentials are not configured.\")\n",
        "\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    # 0) Conexi\u00f3n MetaApi / RPC\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    account  = await connect_metaapi(META_API_TOKEN, ACCOUNT_ID)\n",
        "    rpc_conn = account.get_rpc_connection()\n",
        "    await rpc_conn.connect()\n",
        "\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    # Par\u00e1metros (con defaults tolerantes a faltantes globales)\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    MAGIC = CONFIG.magic\n",
        "    LENGTHS = CONFIG.lengths\n",
        "    SMOOTHS = CONFIG.smooths\n",
        "    LOT_ = CONFIG.lot\n",
        "    COMMENT_ = CONFIG.comment\n",
        "\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    # Helpers locales\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "\n",
        "    def _parse_tf_to_delta(tf: str) -> dt.timedelta:\n",
        "        \"\"\"'1m','5m','15m','1h','4h','1d' \u2192 timedelta (fallback 1m).\"\"\"\n",
        "        tf = (tf or \"1m\").strip().lower()\n",
        "        if tf.endswith(\"mn\"):\n",
        "            tf = tf[:-2] + \"m\"\n",
        "        try:\n",
        "            if tf.endswith(\"m\"):\n",
        "                return dt.timedelta(minutes=max(int(tf[:-1]), 1))\n",
        "            if tf.endswith(\"h\"):\n",
        "                return dt.timedelta(hours=max(int(tf[:-1]), 1))\n",
        "            if tf.endswith(\"d\"):\n",
        "                return dt.timedelta(days=max(int(tf[:-1]), 1))\n",
        "        except Exception:\n",
        "            pass\n",
        "        return dt.timedelta(minutes=1)\n",
        "\n",
        "    def _floor_to_frame(ts: dt.datetime, delta: dt.timedelta) -> dt.datetime:\n",
        "        \"\"\"Floor de ts a m\u00faltiplo exacto del timeframe (UTC).\"\"\"\n",
        "        if ts.tzinfo is None:\n",
        "            ts = ts.replace(tzinfo=dt.timezone.utc)\n",
        "        epoch = dt.datetime(1970, 1, 1, tzinfo=dt.timezone.utc)\n",
        "        secs  = int((ts - epoch).total_seconds())\n",
        "        step  = int(delta.total_seconds()) or 60\n",
        "        return epoch + dt.timedelta(seconds=(secs // step) * step)\n",
        "\n",
        "    def _calc_atr(df: pd.DataFrame, period: int = 14) -> pd.Series:\n",
        "        \"\"\"\n",
        "        ATR estilo Wilder: TR = max(H-L, |H-C1|, |L-C1|), ATR = RMA(TR, period).\n",
        "        Usa ewm(alpha=1/period) como aproximaci\u00f3n de RMA.\n",
        "        \"\"\"\n",
        "        h, l, c = df[\"high\"].astype(float), df[\"low\"].astype(float), df[\"close\"].astype(float)\n",
        "        c1 = c.shift(1)\n",
        "        tr = np.maximum.reduce([\n",
        "            (h - l).to_numpy(),\n",
        "            (h - c1).abs().to_numpy(),\n",
        "            (l - c1).abs().to_numpy()\n",
        "        ])\n",
        "        atr = pd.Series(tr, index=df.index).ewm(alpha=1/period, adjust=False).mean()\n",
        "        return atr.round(4)\n",
        "\n",
        "    async def _has_open_position_magic(rpc_conn, symbol: str, magic: int) -> bool:\n",
        "        \"\"\"True si existe posici\u00f3n con ese magic (prefiere helper global si existe).\"\"\"\n",
        "        try:\n",
        "            pos = await get_pos_with_magic(rpc_conn, symbol=symbol, magic=magic)\n",
        "            return pos is not None\n",
        "        except Exception:\n",
        "            positions = []\n",
        "            try:\n",
        "                positions = await rpc_conn.get_positions(symbol=symbol) or []\n",
        "            except Exception:\n",
        "                positions = []\n",
        "            if not positions:\n",
        "                r = _rest_get_positions(META_API_TOKEN, ACCOUNT_ID, REGION, symbol)\n",
        "                if getattr(r, \"status_code\", 0) == 200:\n",
        "                    try:\n",
        "                        positions = r.json() or []\n",
        "                    except Exception:\n",
        "                        positions = []\n",
        "            if not positions:\n",
        "                return False\n",
        "            for p in positions:\n",
        "                pm = p.get(\"magic\")\n",
        "                cmt = str(p.get(\"comment\") or \"\")\n",
        "                ok = False\n",
        "                if pm is not None:\n",
        "                    try: ok = int(pm) == int(magic)\n",
        "                    except Exception: ok = False\n",
        "                if (not ok) and f\"magic={magic}\" in cmt:\n",
        "                    ok = True\n",
        "                if ok:\n",
        "                    return True\n",
        "            return False\n",
        "\n",
        "    async def _get_api_type(rpc_conn, symbol: str, magic: int):\n",
        "        \"\"\"'Long' / 'Short' / None usando get_pos_with_magic si existe.\"\"\"\n",
        "        side = None\n",
        "        try:\n",
        "            pos = await get_pos_with_magic(rpc_conn, symbol=symbol, magic=magic)\n",
        "            if not pos:\n",
        "                return None\n",
        "            t = pos.get(\"type\")\n",
        "            if isinstance(t, str):\n",
        "                tu = t.upper()\n",
        "                side = \"BUY\" if \"BUY\" in tu else (\"SELL\" if \"SELL\" in tu else None)\n",
        "            elif t == 0:\n",
        "                side = \"BUY\"\n",
        "            elif t == 1:\n",
        "                side = \"SELL\"\n",
        "        except Exception:\n",
        "            try:\n",
        "                positions = await rpc_conn.get_positions(symbol=symbol) or []\n",
        "            except Exception:\n",
        "                positions = []\n",
        "            for p in positions:\n",
        "                pm = p.get(\"magic\")\n",
        "                cmt = str(p.get(\"comment\") or \"\")\n",
        "                ok = False\n",
        "                if pm is not None:\n",
        "                    try: ok = int(pm) == int(magic)\n",
        "                    except Exception: ok = False\n",
        "                if (not ok) and f\"magic={magic}\" in cmt:\n",
        "                    ok = True\n",
        "                if not ok:\n",
        "                    continue\n",
        "                t = p.get(\"type\")\n",
        "                if isinstance(t, str):\n",
        "                    tu = t.upper()\n",
        "                    side = \"BUY\" if \"BUY\" in tu else (\"SELL\" if \"SELL\" in tu else None)\n",
        "                elif t == 0:\n",
        "                    side = \"BUY\"\n",
        "                elif t == 1:\n",
        "                    side = \"SELL\"\n",
        "                break\n",
        "        if side is None:\n",
        "            return None\n",
        "        return \"Long\" if side == \"BUY\" else \"Short\"\n",
        "\n",
        "    def _sync_type_in_df(df_all: pd.DataFrame, api_type: str | None) -> None:\n",
        "        \"\"\"Escribe 'Type' en el bloque activo o en la \u00faltima fila si no se detecta bloque.\"\"\"\n",
        "        if not api_type or df_all.empty:\n",
        "            return\n",
        "        last_oid = df_all.get(\"orderId\")\n",
        "        if last_oid is not None and last_oid.notna().any():\n",
        "            last_oid_val = last_oid.dropna().iloc[-1]\n",
        "            mask = (df_all[\"orderId\"] == last_oid_val)\n",
        "        else:\n",
        "            ed = pd.to_datetime(df_all.get(\"Entry_Date\"), errors=\"coerce\", utc=True)\n",
        "            starts = ed.notna() & (ed != ed.shift(1))\n",
        "            if starts.any():\n",
        "                start_idx = df_all.index[starts].max()\n",
        "                mask = (df_all.index >= start_idx)\n",
        "            else:\n",
        "                mask = pd.Series(False, index=df_all.index)\n",
        "        if mask.any():\n",
        "            df_all.loc[mask, \"Type\"] = api_type\n",
        "        else:\n",
        "            df_all.at[df_all.index[-1], \"Type\"] = api_type\n",
        "\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    # 1) Crear/migrar archivo inicial\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    if not os.path.exists(FILE_PATH):\n",
        "        df = await get_candles_5m(account, start=None, limit=CANDEL_NUMBER)\n",
        "        if len(df) >= 14:\n",
        "            df[\"ATR\"] = _calc_atr(df, 14)\n",
        "        l1, l2, l3, l4 = LENGTHS\n",
        "        s1, s2, s3, s4 = SMOOTHS\n",
        "        generate_trade_signals(df, l1, l2, l3, l4, s1, s2, s3, s4)\n",
        "        _ensure_order_cols(df)\n",
        "        stamp_system_time(df, \"last\")\n",
        "        save_csv(df)\n",
        "        print(f\"\u2714 Archivo inicial creado con {len(df)} velas\")\n",
        "    else:\n",
        "        migrate_csv_if_needed(FILE_PATH)\n",
        "\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    # 2) Loop principal\n",
        "    # \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n",
        "    async def _wait_for_closed_candle(prev_bar: dt.datetime,\n",
        "                                      last_known_time: pd.Timestamp | None,\n",
        "                                      delta: dt.timedelta) -> pd.DataFrame:\n",
        "        \"\"\"Obtiene la \u00faltima vela cerrada <= prev_bar reintentando durante un margen de seguridad.\"\"\"\n",
        "        wait_limit = max(dt.timedelta(seconds=45), delta)\n",
        "        wait_limit = min(wait_limit, dt.timedelta(minutes=5))\n",
        "        deadline = dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc) + wait_limit\n",
        "        poll_sleep = max(3, min(20, int(delta.total_seconds() // 6) or 1))\n",
        "        warned_at: dt.datetime | None = None\n",
        "        latest_candidate: pd.DataFrame | None = None\n",
        "        last_snapshot = pd.DataFrame()\n",
        "        while True:\n",
        "            fresh = await get_candles_5m(account, start=None, limit=50)\n",
        "            fresh = (fresh[fresh[\"time\"] <= prev_bar]\n",
        "                     .drop_duplicates(\"time\")\n",
        "                     .sort_values(\"time\"))\n",
        "            last_snapshot = fresh.copy()\n",
        "            if not fresh.empty:\n",
        "                latest_candidate = fresh.iloc[[-1]].copy()\n",
        "                latest_time = pd.to_datetime(latest_candidate[\"time\"], utc=True, errors=\"coerce\")\n",
        "                latest_time = latest_time.iloc[-1] if not latest_time.empty else None\n",
        "                if last_known_time is None or (latest_time is not None and latest_time > last_known_time):\n",
        "                    return latest_candidate\n",
        "                if (last_known_time is not None\n",
        "                        and latest_time is not None and latest_time <= last_known_time):\n",
        "                    now_warn = dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)\n",
        "                    if warned_at is None or (now_warn - warned_at).total_seconds() >= 60:\n",
        "                        ts_txt = prev_bar.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "                        print(f\"\u26a0\ufe0f Vela cerrada {ts_txt} a\u00fan no publicada; reintentando...\", flush=True)\n",
        "                        warned_at = now_warn\n",
        "            if dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc) >= deadline:\n",
        "                if latest_candidate is not None:\n",
        "                    return latest_candidate\n",
        "                return last_snapshot\n",
        "            await asyncio.sleep(poll_sleep)\n",
        "\n",
        "    reconnect_backoff = 5.0\n",
        "    reconnect_backoff_max = 60.0\n",
        "\n",
        "    last_no_new_warning_at: dt.datetime | None = None\n",
        "    last_no_new_warning_bar: dt.datetime | None = None\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            await asyncio.sleep(seconds_until_next_tf(time_frame_data, offset_sec=3))\n",
        "\n",
        "            now_utc  = dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)\n",
        "            delta    = _parse_tf_to_delta(time_frame_data)\n",
        "            this_bar = _floor_to_frame(now_utc, delta)\n",
        "            prev_bar = this_bar - delta  # \u00faltima vela CERRADA\n",
        "\n",
        "            df_all = _load_csv()\n",
        "            last_known_time = None\n",
        "            if not df_all.empty and \"time\" in df_all.columns:\n",
        "                known_times = pd.to_datetime(df_all[\"time\"], utc=True, errors=\"coerce\").dropna()\n",
        "                if not known_times.empty:\n",
        "                    last_known_time = known_times.iloc[-1]\n",
        "\n",
        "            df_new = await _wait_for_closed_candle(prev_bar, last_known_time, delta)\n",
        "\n",
        "            prev_bar_txt = prev_bar.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "            latest_new_time = None\n",
        "            if not df_new.empty and \"time\" in df_new.columns:\n",
        "                latest_times = pd.to_datetime(df_new[\"time\"], utc=True, errors=\"coerce\").dropna()\n",
        "                if not latest_times.empty:\n",
        "                    latest_new_time = latest_times.iloc[-1]\n",
        "            if last_known_time is not None and (latest_new_time is None or latest_new_time <= last_known_time):\n",
        "                now_warn = dt.datetime.utcnow().replace(tzinfo=dt.timezone.utc)\n",
        "                should_warn = True\n",
        "                if last_no_new_warning_at is not None:\n",
        "                    elapsed = (now_warn - last_no_new_warning_at).total_seconds()\n",
        "                    same_bar = (last_no_new_warning_bar == prev_bar)\n",
        "                    if same_bar and elapsed < 60:\n",
        "                        should_warn = False\n",
        "                if should_warn:\n",
        "                    print(f\"\u26a0\ufe0f Sin nueva vela cerrada para {prev_bar_txt} UTC; se reintentar\u00e1 en el siguiente ciclo.\", flush=True)\n",
        "                    last_no_new_warning_at = now_warn\n",
        "                    last_no_new_warning_bar = prev_bar\n",
        "\n",
        "            existing_times = (\n",
        "                set(pd.to_datetime(df_all[\"time\"], utc=True))\n",
        "                if (not df_all.empty and \"time\" in df_all.columns)\n",
        "                else set()\n",
        "            )\n",
        "\n",
        "            if df_all.empty:\n",
        "                df_all = df_new.copy()\n",
        "            else:\n",
        "                df_all = (pd.concat([df_all, df_new], ignore_index=True)\n",
        "                          .drop_duplicates(\"time\")\n",
        "                          .sort_values(\"time\")\n",
        "                          .reset_index(drop=True))\n",
        "\n",
        "            if len(df_all) >= 14:\n",
        "                df_all[\"ATR\"] = _calc_atr(df_all, 14)\n",
        "\n",
        "            l1, l2, l3, l4 = LENGTHS\n",
        "            s1, s2, s3, s4 = SMOOTHS\n",
        "            generate_trade_signals(df_all, l1, l2, l3, l4, s1, s2, s3, s4)\n",
        "            _ensure_order_cols(df_all)\n",
        "\n",
        "            if not df_new.empty:\n",
        "                new_times = set(pd.to_datetime(df_new[\"time\"], utc=True)) - existing_times\n",
        "                if new_times:\n",
        "                    df_all.loc[pd.to_datetime(df_all[\"time\"], utc=True).isin(new_times), \"source\"] = 1\n",
        "\n",
        "            await open_trade(df_all, rpc_conn, symbol=SYMBOL, lot=LOT_, comment=COMMENT_, magic=MAGIC)\n",
        "\n",
        "            api_type = await _get_api_type(rpc_conn, SYMBOL, MAGIC)\n",
        "            _sync_type_in_df(df_all, api_type)\n",
        "            await sync_stop_loss_from_df(df_all, rpc_conn, symbol=SYMBOL, magic=MAGIC)\n",
        "\n",
        "            stamp_system_time(df_all, \"last\")\n",
        "            save_csv(df_all)\n",
        "            print(dt.datetime.utcnow().strftime(\"%H:%M:%S\"), \"| actualizaci\u00f3n (ciclo \"+time_frame_data+\")\")\n",
        "\n",
        "            reconnect_backoff = 5.0\n",
        "        except asyncio.CancelledError:\n",
        "            raise\n",
        "        except Exception as loop_err:\n",
        "            logging.exception(\"Error en ciclo principal MetaApi: %s\", loop_err)\n",
        "            print(f\"\u26a0\ufe0f Error en ciclo principal: {loop_err}\", flush=True)\n",
        "            await asyncio.sleep(reconnect_backoff)\n",
        "            reconnect_backoff = min(reconnect_backoff * 2, reconnect_backoff_max)\n",
        "            try:\n",
        "                account = await connect_metaapi(META_API_TOKEN, ACCOUNT_ID)\n",
        "                rpc_conn = account.get_rpc_connection()\n",
        "                try:\n",
        "                    await rpc_conn.connect()\n",
        "                except Exception:\n",
        "                    pass\n",
        "                try:\n",
        "                    await asyncio.wait_for(rpc_conn.wait_synchronized(), timeout=30)\n",
        "                except Exception:\n",
        "                    pass\n",
        "                reconnect_backoff = 5.0\n",
        "                print(\"\ud83d\udd04 Reconexi\u00f3n MetaApi completada.\", flush=True)\n",
        "            except Exception as recon_err:\n",
        "                logging.exception(\"Fallo reconectando a MetaApi: %s\", recon_err)\n",
        "                print(f\"\u274c Fall\u00f3 la reconexi\u00f3n a MetaApi: {recon_err}\", flush=True)\n",
        "            continue\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "W481PrVufZ8Z",
      "metadata": {
        "id": "W481PrVufZ8Z"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yI6v2q_xfRtg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yI6v2q_xfRtg",
        "outputId": "1648fe99-4abe-41c6-c45f-11ac7e8a0d60"
      },
      "outputs": [],
      "source": [
        "df_plot_source = globals().get(\"df\")\n",
        "if isinstance(df_plot_source, pd.DataFrame) and not df_plot_source.empty:\n",
        "    df_plot = df_plot_source.tail(250).copy()\n",
        "\n",
        "    plt.figure(figsize=(14, 7))\n",
        "    plt.plot(df_plot['time'], df_plot['close'], label='Close', color='black', linewidth=1)\n",
        "    plt.plot(df_plot['time'], df_plot['kal_1'], label='Kal_1', color='blue', linestyle='--')\n",
        "    plt.plot(df_plot['time'], df_plot['kal_2'], label='Kal_2', color='red', linestyle='--')\n",
        "    plt.plot(df_plot['time'], df_plot['kal_3'], label='Kal_3', color='green', linestyle='--')\n",
        "\n",
        "    for _, row in df_plot.iterrows():\n",
        "        if row.get('Open_Trade') == 1:\n",
        "            plt.axvline(row['time'], color='blue', linestyle='-', linewidth=1, alpha=0.7)\n",
        "        elif row.get('Open_Trade') == -1:\n",
        "            plt.axvline(row['time'], color='red', linestyle='-', linewidth=1, alpha=0.7)\n",
        "\n",
        "    plt.title('Close Price and Kalman Lines with Trade Signals')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Price')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No data available to plot Kalman signals.\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}